# ğŸ—ï¸ KIáº¾N TRÃšC Tá»”NG QUAN - MODULE 5: HEART DISEASE PREDICTION

## ğŸ“‹ **Má»¤C Lá»¤C**
1. [Tá»•ng Quan Há»‡ Thá»‘ng](#1-tá»•ng-quan-há»‡-thá»‘ng)
2. [Cáº¥u TrÃºc ThÆ° Má»¥c](#2-cáº¥u-trÃºc-thÆ°-má»¥c)
3. [Chi Tiáº¿t Tá»«ng Component](#3-chi-tiáº¿t-tá»«ng-component)
4. [Workflow Diagram](#4-workflow-diagram)
5. [Data Flow](#5-data-flow)

---

## **1. Tá»”NG QUAN Há»† THá»NG**

Há»‡ thá»‘ng dá»± Ä‘oÃ¡n bá»‡nh tim sá»­ dá»¥ng **Multimodal Fusion Model** káº¿t há»£p:
- ğŸ“Š **Numerical Data**: 70,000 bá»‡nh nhÃ¢n (Sulianova dataset)
- ğŸ¥ **Video Data**: 10,000 video siÃªu Ã¢m tim (EchoNet-Dynamic)
- ğŸ§  **Deep Learning**: MLP + ResNet-50 CNN + Fusion Layer
- ğŸš€ **Production API**: FastAPI vá»›i video selection thÃ´ng minh

---

## **2. Cáº¤U TRÃšC THá»¨ Má»¤C**

```
Module5/
â”œâ”€â”€ ğŸ““ heart_prediction.ipynb       # Notebook huáº¥n luyá»‡n & testing
â”œâ”€â”€ ğŸ“Š cleveland.csv                # Dataset y táº¿ (backup)
â”œâ”€â”€ ğŸ“ fusion_results.json          # Káº¿t quáº£ 5-fold CV
â”œâ”€â”€ ğŸ“„ requirements.txt             # Dependencies
â”‚
â”œâ”€â”€ ğŸ“‚ api/                         # â­ PRODUCTION API
â”‚   â”œâ”€â”€ main.py                     # FastAPI endpoints
â”‚   â”œâ”€â”€ ğŸ“ utility/                 # Core logic
â”‚   â”‚   â”œâ”€â”€ model.py                # Model architecture
â”‚   â”‚   â”œâ”€â”€ load_model.py           # Load weights & scalers
â”‚   â”‚   â”œâ”€â”€ load_data.py            # Load datasets
â”‚   â”‚   â”œâ”€â”€ preprocessing.py        # Preprocessing pipeline
â”‚   â”‚   â”œâ”€â”€ predict.py              # Prediction logic
â”‚   â”‚   â””â”€â”€ feature_engineer.py     # Feature engineering
â”‚   â”œâ”€â”€ ğŸ“ test/                    # Unit tests
â”‚   â”œâ”€â”€ start_api.bat/sh            # Startup scripts
â”‚   â””â”€â”€ ğŸ“š Documentation/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ API_USAGE_GUIDE.md
â”‚       â”œâ”€â”€ VIDEO_SELECTION_GUIDE.md
â”‚       â””â”€â”€ CODE_DOCUMENTATION_SUMMARY.md
â”‚
â”œâ”€â”€ ğŸ“‚ data/                        # â­ PREPROCESSED DATA
â”‚   â”œâ”€â”€ echonet_features.npy        # CNN features (10000Ã—64)
â”‚   â”œâ”€â”€ echonet_labels.npy          # Ground truth labels
â”‚   â””â”€â”€ echonet_features2.npy       # Alternative features
â”‚
â”œâ”€â”€ ğŸ“‚ models/                      # â­ TRAINED MODELS
â”‚   â”œâ”€â”€ best_fusion_model.pth       # Best model weights
â”‚   â”œâ”€â”€ fusion_model_fold_*.pth     # 5-fold models
â”‚   â”œâ”€â”€ num_scaler_fold_*.pkl       # Numerical scalers
â”‚   â””â”€â”€ cnn_scaler_fold_*.pkl       # CNN feature scalers
â”‚
â””â”€â”€ ğŸ“‚ ui/                          # Frontend (if exists)
```

---

## **3. CHI TIáº¾T Tá»ªNG COMPONENT**

### **ğŸ“‚ A. API FOLDER** (`api/`) - **TRá»ŒNG TÃ‚M**

ÄÃ¢y lÃ  **production deployment** vá»›i FastAPI, cung cáº¥p REST API cho dá»± Ä‘oÃ¡n bá»‡nh tim.

#### **ğŸ”§ A1. Core Files**

##### **`main.py`** - FastAPI Application
**Chá»©c nÄƒng chÃ­nh:**
- **Endpoints:**
  - `GET /` - API information
  - `GET /health` - Health check
  - `GET /videos` - List available videos (pagination)
  - `GET /videos/search` - Search videos by filename
  - `POST /predict` - Single prediction
  - `POST /predict/batch` - Batch predictions

**Äáº·c Ä‘iá»ƒm ná»•i báº­t:**
```python
# Flexible video selection
{
    "patient_data": {...},
    "video_index": 2           # Option 1: By index
    # OR
    "video_filename": "0X10...avi"  # Option 2: By filename
}
```

**Models:**
- `PatientData`: 13 fields (age, gender, height, weight, BP, cholesterol...)
  - Auto-convert age: years â†’ days (50 years â†’ 18,250 days)
- `PredictionRequest`: patient_data + video selection
- `PredictionResponse`: prediction + probability + confidence + metadata

---

#### **ğŸ› ï¸ A2. Utility Package** (`api/utility/`)

##### **`model.py`** - Model Architecture
```python
class NumericalMLP(nn.Module):
    """MLP cho 28 numerical features"""
    Input: (batch, 28) â†’ [128, 64] â†’ Output: (batch, 64)

class FeatureFusionModel(nn.Module):
    """Multimodal fusion"""
    Inputs:
        - Numerical: (batch, 28) â†’ MLP â†’ (batch, 64)
        - CNN: (batch, 64) â†’ Identity
    Fusion: Concat(64, 64) â†’ [128, 64] â†’ Classifier â†’ (batch, 2)
```

**Kiáº¿n trÃºc:**
```
Numerical Features (28) â”€â”€â†’ MLP â”€â”€â†’ (64)
                                      â”œâ”€â”€â†’ Fusion Layer â”€â”€â†’ Classifier â”€â”€â†’ (2)
CNN Features (64) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ (64)
```

##### **`load_model.py`** - Model & Scaler Loading
```python
# Load trained model
fusion_model = FeatureFusionModel(numerical_dim=28, cnn_dim=64)
fusion_model.load_state_dict(torch.load('best_fusion_model.pth'))

# Load scalers
num_scaler = pickle.load('num_scaler_fold_1.pkl')    # StandardScaler (28 features)
cnn_scaler = pickle.load('cnn_scaler_fold_1.pkl')    # StandardScaler (64 features)

# Load fixed CNN model (ResNet-50)
cnn_model = FixedCNNFeatureExtractor()
```

##### **`load_data.py`** - Dataset Loading
```python
# Load Sulianova dataset (70,000 patients)
sulianova_data = kagglehub.dataset_load(
    "sulianova/cardiovascular-disease-dataset",
    file_path="cardio_train.csv"
)

# Load EchoNet-Dynamic (10,000 videos)
def load_echonet_with_kagglehub():
    """Returns: (FileList, VolumeTracings, Videos_path)"""
    # FileList.csv: 10,030 videos with metadata
    # Videos/: .avi video files
```

##### **`feature_engineer.py`** - Feature Engineering
```python
def preprocess_and_engineer_features(df):
    """
    28 features from 13 raw features:
    - Basic: age, gender, height, weight, BP, cholesterol, gluc
    - Derived: BMI, MAP, PP, cholesterol_ratio, etc.
    - Interactions: bmi_x_age, map_x_age, pp_x_age, etc.
    """
    # Age in years
    df['age_years'] = df['age'] / 365

    # BMI
    df['bmi'] = df['weight'] / ((df['height']/100)**2)

    # MAP (Mean Arterial Pressure)
    df['map'] = (df['ap_hi'] + 2*df['ap_lo']) / 3

    # ... + 20 more features
    return X (28 features), y (labels)
```

##### **`preprocessing.py`** - Preprocessing Pipeline
```python
def preprocessing_pipeline(sample_json, video_index, ...):
    """
    STEP 1: Numerical Data
        1. Convert JSON â†’ DataFrame
        2. Feature engineering (13 â†’ 28 features)
        3. Scale with num_scaler
        4. Convert to tensor

    STEP 2: CNN Features
        Option A: Load pre-extracted features
            - echonet_features.npy[video_index]
        Option B: Extract on-the-fly
            - Read video file
            - Extract frames
            - CNN inference â†’ 64 features
        5. Scale with cnn_scaler
        6. Convert to tensor

    STEP 3: Prepare for model
        - Move to device (CPU/CUDA)
        - Return: (numerical_tensor, cnn_tensor, metadata)
    """
```

##### **`predict.py`** - Prediction Logic
```python
def predict_single_sample(sample_json, video_index, ...):
    """
    1. Preprocess data (numerical + video)
    2. Model inference
    3. Softmax â†’ probabilities
    4. Return: (prediction, probability, info)
    """
    # Preprocess
    numerical_input, cnn_input, info = preprocessing_pipeline(...)

    # Predict
    fusion_model.eval()
    with torch.no_grad():
        outputs, _ = fusion_model(numerical_input, cnn_input)
        probabilities = torch.softmax(outputs, dim=1)
        prediction = outputs.argmax(dim=1).item()
        disease_prob = probabilities[0, 1].item()

    return prediction, disease_prob, info
```

---

#### **ğŸ“š A3. Documentation Files**

| File | Ná»™i Dung |
|------|----------|
| `README.md` | HÆ°á»›ng dáº«n setup & deployment |
| `API_USAGE_GUIDE.md` | CÃ¡ch sá»­ dá»¥ng API, examples vá»›i requests/curl |
| `VIDEO_SELECTION_GUIDE.md` | HÆ°á»›ng dáº«n chá»n video (index vs filename) |
| `CODE_DOCUMENTATION_SUMMARY.md` | Giáº£i thÃ­ch code comments Ä‘Ã£ thÃªm |
| `QUICKSTART.txt` | Quick start guide |

---

### **ğŸ“‚ B. DATA FOLDER** (`data/`)

Chá»©a **pre-extracted CNN features** Ä‘á»ƒ tÄƒng tá»‘c inference.

```python
# echonet_features.npy
Shape: (10000, 64)
Content: ResNet-50 features cho 10,000 videos
Size: ~5MB (thay vÃ¬ 7.3GB videos)

# echonet_labels.npy
Shape: (10000,)
Content: Ground truth labels (ejection fraction, etc.)
```

**Lá»£i Ã­ch:**
- âœ… **Fast inference**: KhÃ´ng cáº§n cháº¡y CNN má»—i láº§n predict
- âœ… **Memory efficient**: 5MB vs 7.3GB
- âœ… **Reproducible**: CÃ¹ng features cho má»i prediction

**CÃ¡ch táº¡o:**
```python
# Trong notebook (cell trÃ­ch xuáº¥t features)
cnn_features = []
for video_path in video_paths:
    features = cnn_model.extract_features(video_path)
    cnn_features.append(features)

np.save('echonet_features.npy', np.array(cnn_features))
```

---

### **ğŸ“‚ C. MODELS FOLDER** (`models/`)

Chá»©a **trained model weights** vÃ  **scalers** tá»« 5-fold cross-validation.

```
models/
â”œâ”€â”€ best_fusion_model.pth          # Model tá»‘t nháº¥t (fold vá»›i highest accuracy)
â”‚
â”œâ”€â”€ fusion_model_fold_1.pth        # Fold 1 weights
â”œâ”€â”€ fusion_model_fold_2.pth        # Fold 2 weights
â”œâ”€â”€ fusion_model_fold_3.pth        # Fold 3 weights
â”œâ”€â”€ fusion_model_fold_4.pth        # Fold 4 weights
â”œâ”€â”€ fusion_model_fold_5.pth        # Fold 5 weights
â”‚
â”œâ”€â”€ num_scaler_fold_1.pkl          # Numerical scaler (StandardScaler)
â”œâ”€â”€ num_scaler_fold_2.pkl          #   - mean: (28,)
â”œâ”€â”€ num_scaler_fold_3.pkl          #   - std: (28,)
â”œâ”€â”€ num_scaler_fold_4.pkl
â”œâ”€â”€ num_scaler_fold_5.pkl
â”‚
â”œâ”€â”€ cnn_scaler_fold_1.pkl          # CNN feature scaler (StandardScaler)
â”œâ”€â”€ cnn_scaler_fold_2.pkl          #   - mean: (64,)
â”œâ”€â”€ cnn_scaler_fold_3.pkl          #   - std: (64,)
â”œâ”€â”€ cnn_scaler_fold_4.pkl
â””â”€â”€ cnn_scaler_fold_5.pkl
```

**File sizes:**
- `.pth` files: ~1-5MB (model weights)
- `.pkl` files: ~1-5KB (scaler parameters)

**Ná»™i dung state_dict:**
```python
torch.load('best_fusion_model.pth'):
{
    'numerical_mlp.mlp.0.weight': tensor(128, 28),
    'numerical_mlp.mlp.0.bias': tensor(128),
    'numerical_mlp.mlp.3.weight': tensor(64, 128),
    'numerical_mlp.mlp.3.bias': tensor(64),
    'fusion_layer.0.weight': tensor(128, 128),
    'fusion_layer.0.bias': tensor(128),
    'fusion_layer.3.weight': tensor(64, 128),
    'fusion_layer.3.bias': tensor(64),
    'classifier.0.weight': tensor(32, 64),
    'classifier.0.bias': tensor(32),
    'classifier.3.weight': tensor(2, 32),
    'classifier.3.bias': tensor(2)
}
```

---

### **ğŸ““ D. NOTEBOOK** (`heart_prediction.ipynb`)

**Má»¥c Ä‘Ã­ch:**
- ğŸ§ª **Experimentation & Training**
- ğŸ“Š **Model Evaluation**
- ğŸ§ª **Testing & Validation**

**Ná»™i dung chÃ­nh:**

#### **Section 1: Data Loading & EDA**
```python
# Load Sulianova dataset
sulianova_data = load_sulianova()  # 70,000 patients

# Load EchoNet dataset
echonet_filelist, videos_path = load_echonet()  # 10,000 videos

# EDA
print(sulianova_data.describe())
visualize_distributions()
check_missing_values()
```

#### **Section 2: Feature Engineering**
```python
# Create 28 features from 13 raw features
X, y, feature_names = preprocess_and_engineer_features(sulianova_data)

# Features:
# - Basic: age_years, gender, height, weight, ...
# - Derived: bmi, map, pp, pulse_pressure_ratio, ...
# - Interactions: bmi_x_age, map_x_age, ...
```

#### **Section 3: CNN Feature Extraction**
```python
# Extract ResNet-50 features from videos
cnn_model = FixedCNNFeatureExtractor()

echonet_features = []
for video_path in video_paths:
    features = extract_video_features(video_path, cnn_model)
    echonet_features.append(features)

# Save for reuse
np.save('data/echonet_features.npy', echonet_features)
```

#### **Section 4: Model Training (5-Fold CV)**
```python
# 5-fold cross-validation
fusion_results = train_fusion_model_with_cv(
    numerical_X=X,              # (70000, 28)
    numerical_y=y,              # (70000,)
    cnn_features=echonet_features,  # (10000, 64)
    n_folds=5,
    epochs=50,
    batch_size=64
)

# Save each fold
for fold_result in fusion_results['fold_results']:
    fold_num = fold_result['fold']
    model = fold_result['model']

    # Save model
    torch.save(model.state_dict(),
               f'models/fusion_model_fold_{fold_num}.pth')

    # Save scalers
    pickle.dump(fold_result['num_scaler'],
                f'models/num_scaler_fold_{fold_num}.pkl')
    pickle.dump(fold_result['cnn_scaler'],
                f'models/cnn_scaler_fold_{fold_num}.pkl')
```

#### **Section 5: Model Evaluation**
```python
# Metrics per fold
for fold_result in fusion_results['fold_results']:
    print(f"Fold {fold_result['fold']}:")
    print(f"  Train Acc: {fold_result['train_accuracy']:.4f}")
    print(f"  Val Acc: {fold_result['val_accuracy']:.4f}")
    print(f"  Val Loss: {fold_result['val_loss']:.4f}")

# Select best model
best_fold = max(fusion_results['fold_results'],
                key=lambda x: x['val_accuracy'])
```

#### **Section 6: Testing & Inference**
```python
# Test single prediction
sample_patient = {
    "id": 12345,
    "age": 50,
    "gender": 2,
    "height": 168,
    "weight": 62.0,
    "ap_hi": 110,
    "ap_lo": 80,
    "cholesterol": 1,
    "gluc": 1,
    "smoke": 0,
    "alco": 0,
    "active": 1
}

prediction, probability, info = predict_single_sample(
    sample_json=sample_patient,
    video_index=0,
    fusion_model=fusion_model,
    num_scaler=num_scaler,
    cnn_scaler=cnn_scaler
)

print(f"Prediction: {prediction}")
print(f"Disease Probability: {probability:.2%}")
```

---

## **4. WORKFLOW DIAGRAM**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                           TRAINING WORKFLOW                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: DATA LOADING                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    [Sulianova Dataset]              [EchoNet Dataset]
     (70,000 patients)                (10,000 videos)
           â”‚                                  â”‚
           â”‚                                  â”‚
           â–¼                                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Load CSV    â”‚                  â”‚ Load Videos    â”‚
    â”‚ via         â”‚                  â”‚ via            â”‚
    â”‚ KaggleHub   â”‚                  â”‚ KaggleHub      â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                  â”‚
           â”‚                                  â”‚
           â–¼                                  â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: FEATURE ENGINEERING                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    [Raw Features: 13]               [Video Files (.avi)]
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
    â”‚ age, gender,     â”‚                    â”‚
    â”‚ height, weight,  â”‚                    â–¼
    â”‚ ap_hi, ap_lo,    â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ cholesterol,     â”‚          â”‚ ResNet-50 CNN        â”‚
    â”‚ gluc, smoke,     â”‚          â”‚ Feature Extractor    â”‚
    â”‚ alco, active     â”‚          â”‚ (Pre-trained)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  (Raw features combine                      â”‚
   with engineered feature)                  â”‚
             â–¼                               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Feature Engineering â”‚        â”‚ Extract Features    â”‚
    â”‚ â€¢ BMI, MAP, PP      â”‚        â”‚ â€¢ 10 frames/video   â”‚
    â”‚ â€¢ Ratios            â”‚        â”‚ â€¢ Average pooling   â”‚
    â”‚ â€¢ Interactions      â”‚        â”‚ â€¢ Output: (10k, 64) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
			â”‚                                â”‚
			â–¼                                â–¼
    [Engineered: 28 features]     [CNN Features: 64 dims]
             â”‚                               â”‚
             â”‚                               â–¼
             â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚                    â”‚ Save Features        â”‚
             â”‚                    â”‚ echonet_features.npy â”‚
             â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: PREPROCESSING & SCALING                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    [Numerical: 28]               [CNN Features: 64]
           â”‚                              â”‚
           â–¼                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ StandardScaler  â”‚          â”‚ StandardScaler  â”‚
    â”‚ Fit on Train    â”‚          â”‚ Fit on Train    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                            â”‚
             â–¼                            â–¼
    [Scaled Numerical]            [Scaled CNN]
             â”‚                            â”‚
             â”‚                            â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: MODEL TRAINING (5-Fold CV)                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Fusion Model         â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    [Numerical] â”€â”€â†’ â”‚  â”‚ Numerical MLP    â”‚  â”‚
       (28)         â”‚  â”‚ [128] â†’ [64]     â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚           â”‚            â”‚
                    â”‚           â–¼            â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚ Fusion Layer     â”‚  â”‚
                    â”‚  â”‚ Concat(64+64)    â”‚  â”‚
    [CNN] â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚  â”‚ â†’ [128] â†’ [64]   â”‚  â”‚
       (64)         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚           â”‚            â”‚
                    â”‚           â–¼            â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚ Classifier       â”‚  â”‚
                    â”‚  â”‚ [64] â†’ [32] â†’ 2  â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚           â”‚            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Output: (Disease, 0/1)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                          Training Loop:
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Fold 1: Train & Val  â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ Fold 2: Train & Val  â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ Fold 3: Train & Val  â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ Fold 4: Train & Val  â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ Fold 5: Train & Val  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: MODEL SAVING                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    For Each Fold (1-5):
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Save Model Weights     â”‚
                    â”‚ fusion_model_fold_k.pthâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Save Num Scaler        â”‚
                    â”‚ num_scaler_fold_k.pkl  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Save CNN Scaler        â”‚
                    â”‚ cnn_scaler_fold_k.pkl  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    Select Best Fold:
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Copy to:               â”‚
                    â”‚ best_fusion_model.pth  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          INFERENCE WORKFLOW (API)                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: API REQUEST                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Client (Browser/Postman/Code)
           â”‚
           â”‚ POST /predict
           â”‚ {
           â”‚   "patient_data": {
           â”‚     "age": 50,
           â”‚     "gender": 2,
           â”‚     "height": 168,
           â”‚     ...
           â”‚   },
           â”‚   "video_filename": "0X1005D03EED19C65B.avi"
           â”‚ }
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ FastAPI Server â”‚
    â”‚ (main.py)      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: DATA VALIDATION                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Pydantic Validation  â”‚
    â”‚ â€¢ Age: yearsâ†’days    â”‚
    â”‚ â€¢ BP: valid range    â”‚
    â”‚ â€¢ Video: filenameâ†’idxâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Load Models/Scalers  â”‚
    â”‚ â€¢ fusion_model.pth   â”‚
    â”‚ â€¢ num_scaler.pkl     â”‚
    â”‚ â€¢ cnn_scaler.pkl     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: PREPROCESSING                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    [Patient Data]              [Video Index]
         â”‚                            â”‚
         â–¼                            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Feature Eng.    â”‚      â”‚ Load CNN Featuresâ”‚
    â”‚ 13 â†’ 28 featuresâ”‚      â”‚ from .npy file   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                        â”‚
             â–¼                        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ num_scaler      â”‚      â”‚ cnn_scaler       â”‚
    â”‚ .transform()    â”‚      â”‚ .transform()     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                        â”‚
             â–¼                        â–¼
    [Scaled Numerical (28)]   [Scaled CNN (64)]
             â”‚                        â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: MODEL INFERENCE                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Fusion Model      â”‚
                    â”‚  .eval() mode      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Forward Pass       â”‚
                    â”‚ (no gradient)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Softmax            â”‚
                    â”‚ â†’ Probabilities    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Argmax             â”‚
                    â”‚ â†’ Prediction (0/1) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: RESPONSE                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Build Response     â”‚
                    â”‚ {                  â”‚
                    â”‚   prediction: 0,   â”‚
                    â”‚   label: "No Dis", â”‚
                    â”‚   probability: 0.12â”‚
                    â”‚   confidence: 0.88 â”‚
                    â”‚ }                  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ JSON Response      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                         Client Receives
```

---

## **5. DATA FLOW**

### **ğŸ“Š Training Data Flow**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Sulianova Dataset (70,000 patients)                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Raw: id, age, gender, height, weight, ap_hi, ap_lo,          â”‚ â”‚
â”‚ â”‚      cholesterol, gluc, smoke, alco, active, cardio          â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                      â”‚
â”‚                           â–¼                                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Feature Engineering: 13 â†’ 28 features                        â”‚ â”‚
â”‚ â”‚ â€¢ age_years, bmi, map, pp, pulse_pressure_ratio              â”‚ â”‚
â”‚ â”‚ â€¢ cholesterol_ratio, gluc_ratio, bp_age_interaction          â”‚ â”‚
â”‚ â”‚ â€¢ bmi_x_age, map_x_age, pp_x_age, etc.                       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                      â”‚
â”‚                           â–¼                                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ StandardScaler Fit                                           â”‚ â”‚
â”‚ â”‚ X_scaled = (X - mean) / std                                  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EchoNet Dataset (10,000 videos)                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Videos: *.avi files (7.3GB total)                            â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                      â”‚
â”‚                           â–¼                                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ResNet-50 Feature Extraction                                 â”‚ â”‚
â”‚ â”‚ â€¢ Sample 10 frames per video                                 â”‚ â”‚
â”‚ â”‚ â€¢ Extract features: (10, 64)                                 â”‚ â”‚
â”‚ â”‚ â€¢ Average pooling: (64,)                                     â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                      â”‚
â”‚                           â–¼                                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Save Features: echonet_features.npy (10000, 64)              â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                      â”‚
â”‚                           â–¼                                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ StandardScaler Fit                                           â”‚ â”‚
â”‚ â”‚ CNN_scaled = (CNN - mean) / std                              â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                          â”‚                         â”‚
         â–¼                          â–¼                         â–¼
[Numerical Scaled (28)]   [CNN Scaled (64)]         [Labels (70k)]
         â”‚                          â”‚                         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ 5-Fold Cross-Val     â”‚
              â”‚ Train Fusion Model   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Save:                â”‚
              â”‚ â€¢ Model weights (.pth)
              â”‚ â€¢ Scalers (.pkl)     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **ğŸš€ Inference Data Flow**

```
User Input                                    API Response
    â”‚                                              â–²
    â”‚ POST /predict                                â”‚
    â–¼                                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚ Patient Data       â”‚                             â”‚
â”‚ {                  â”‚                             â”‚
â”‚   age: 50,         â”‚                             â”‚
â”‚   gender: 2,       â”‚                             â”‚
â”‚   height: 168,     â”‚                             â”‚
â”‚   ...              â”‚                             â”‚
â”‚   video: "0X10..." â”‚                             â”‚
â”‚ }                  â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
          â”‚                                        â”‚
          â–¼                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚ Validation         â”‚                             â”‚
â”‚ â€¢ Pydantic models  â”‚                             â”‚
â”‚ â€¢ Age: yearsâ†’days  â”‚                             â”‚
â”‚ â€¢ Video: nameâ†’idx  â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
          â”‚                                        â”‚
          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
          â–¼               â–¼                â–¼       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ Feature Eng. â”‚  â”‚ Load CNN     â”‚  â”‚ Load     â”‚   â”‚
â”‚ 13 â†’ 28      â”‚  â”‚ Features     â”‚  â”‚ Models   â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
       â”‚                 â”‚                â”‚        â”‚
       â–¼                 â–¼                â–¼        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ num_scaler   â”‚  â”‚ cnn_scaler   â”‚  â”‚ fusion   â”‚   â”‚
â”‚ .transform() â”‚  â”‚ .transform() â”‚  â”‚ model    â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
       â”‚                 â”‚                â”‚        â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
                â–¼                                  â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
       â”‚ Model Inference â”‚                         â”‚
       â”‚ â€¢ Forward pass  â”‚                         â”‚
       â”‚ â€¢ Softmax       â”‚                         â”‚
       â”‚ â€¢ Argmax        â”‚                         â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
                â”‚                                  â”‚
                â–¼                                  â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
       â”‚ Response        â”‚                         â”‚
       â”‚ {               â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚   prediction: 0 â”‚
       â”‚   label: "..."  â”‚
       â”‚   prob: 0.12    â”‚
       â”‚   conf: 0.88    â”‚
       â”‚ }               â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **6. Tá»”NG Káº¾T**

### **ğŸ¯ Äiá»ƒm Máº¡nh Cá»§a Kiáº¿n TrÃºc**

1. **Modular Design**
   - âœ… TÃ¡ch biá»‡t training (notebook) vÃ  production (API)
   - âœ… Utility package cÃ³ thá»ƒ tÃ¡i sá»­ dá»¥ng
   - âœ… Dá»… maintain vÃ  extend

2. **Performance Optimization**
   - âœ… Pre-extract CNN features â†’ Fast inference
   - âœ… Cached scalers â†’ Consistent preprocessing
   - âœ… 5-fold CV â†’ Robust model selection

3. **Production Ready**
   - âœ… FastAPI vá»›i auto-documentation (Swagger)
   - âœ… Flexible video selection (index/filename)
   - âœ… Comprehensive error handling
   - âœ… Health check endpoint

4. **Scalability**
   - âœ… Batch prediction support
   - âœ… Pagination for video listing
   - âœ… Search functionality
   - âœ… Easy to add new features

### **ğŸ“Œ Workflow Summary**

```
TRAINING:
Notebook â†’ Feature Engineering â†’ Model Training â†’ Save Weights/Scalers

DEPLOYMENT:
API Startup â†’ Load Models â†’ Wait for Requests

INFERENCE:
Request â†’ Validate â†’ Preprocess â†’ Predict â†’ Response
```

### **ğŸ” Key Files to Remember**

| Component | Files | Purpose |
|-----------|-------|---------|
| **Model Architecture** | `api/utility/model.py` | Define NumericalMLP & FeatureFusionModel |
| **Training** | `heart_prediction.ipynb` | Train, evaluate, save models |
| **Weights** | `models/*.pth` | Trained model parameters |
| **Scalers** | `models/*.pkl` | Preprocessing statistics |
| **Features** | `data/*.npy` | Pre-extracted CNN features |
| **API** | `api/main.py` | Production endpoints |
| **Preprocessing** | `api/utility/preprocessing.py` | Data pipeline |
| **Prediction** | `api/utility/predict.py` | Inference logic |

---

**ğŸ‰ Há»‡ thá»‘ng hoÃ n chá»‰nh tá»« nghiÃªn cá»©u (notebook) Ä‘áº¿n production (API)!**
