{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSfu68BbnJSU"
      },
      "source": [
        "## **Tóm tắt những phần thay đổi**\n",
        "\n",
        "1. **Phần import thư viện thêm:**\n",
        "\n",
        "   ```python\n",
        "   import nltk\n",
        "   nltk.download('wordnet', quiet=True)\n",
        "   nltk.download('omw-1.4', quiet=True)\n",
        "   ```\n",
        "\n",
        "2. **Những phần có ghi \"**bản mới\"**\" sẽ *thay thế cho các đoạn code đánh dấu \"bản cũ\"***, và **không dùng đến các đoạn *bản cũ* nữa**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GoHZscs3bfnu",
        "outputId": "32967821-5f35-43bb-8501-68bfa83da51f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gtBORZTRJaws",
        "outputId": "e98fb8bd-8d16-4635-f2e2-c2663cee3612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flaml\n",
            "  Downloading FLAML-2.3.5-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: NumPy>=1.17 in /usr/local/lib/python3.11/dist-packages (from flaml) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.7.14)\n",
            "Downloading FLAML-2.3.5-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: flaml\n",
            "Successfully installed flaml-2.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install flaml kagglehub pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRbEWLxLaUu6",
        "outputId": "eaa38afb-2749-45d9-9e64-435734485e40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import faiss\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "import re\n",
        "import warnings\n",
        "import gdown\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeYSxDGjNBF4"
      },
      "source": [
        "##Data Augmentation (bản mới)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hQOIgGuIU9Y0"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# Class sinh dữ liệu tinh vi để augmentation\n",
        "# ==============================\n",
        "import pandas as pd\n",
        "import random\n",
        "from nltk.corpus import wordnet\n",
        "import requests\n",
        "\n",
        "class HardExampleGenerator:\n",
        "    def __init__(self, dataset_path, alpha_spam=0.5, alpha_ham=0.3, use_llm_phrases=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataset_path (str): đường dẫn file CSV chứa cột 'Message' và 'Category'\n",
        "            alpha_spam (float): tỷ lệ nhân bản spam khi augment\n",
        "            alpha_ham (float): tỷ lệ nhân bản ham khi augment\n",
        "            use_llm_phrases (bool): nếu True thì chờ load LLM phrases sau bằng load_llm_phrases()\n",
        "        \"\"\"\n",
        "        self.dataset_path = dataset_path\n",
        "        self.alpha_spam = alpha_spam\n",
        "        self.alpha_ham = alpha_ham\n",
        "        self.df = pd.read_csv(dataset_path)\n",
        "\n",
        "        # Nếu chưa có LLM phrases thì dùng cụm mặc định\n",
        "        if not use_llm_phrases:\n",
        "            self.spam_groups = self._init_spam_phrases()\n",
        "            self.ham_groups = self._init_ham_phrases()\n",
        "        else:\n",
        "            # Khởi tạo rỗng, sau sẽ gán bằng load_llm_phrases()\n",
        "            self.spam_groups = []\n",
        "            self.ham_groups = []\n",
        "\n",
        "    # Dùng cho cách 2 (có thể lấy từ LLM bên ngoài xịn hơn)\n",
        "    def _init_spam_phrases(self):\n",
        "        # Các cụm spam tinh vi (giống file gốc)\n",
        "        # ----- 7 nhóm dấu hiệu spam -----\n",
        "        financial_phrases = [\n",
        "            \"you get $100 back\", \"they refund $200 instantly\",\n",
        "            \"limited $50 bonus for early registration\", \"earn $150/day remote work\",\n",
        "            \"approved for a $500 credit\", \"quick $300 refund if you confirm\",\n",
        "            \"they give $250 cashback if you check in early\",\n",
        "            \"your account gets $100 instantly after confirmation\",\n",
        "            \"instant $400 transfer if you reply YES today\",\n",
        "            \"exclusive $600 grant approved for you\"\n",
        "        ]\n",
        "\n",
        "        promotion_phrases = [\n",
        "            \"limited time offer ends tonight\", \"buy one get one free today only\",\n",
        "            \"exclusive deal just for you\", \"hot sale up to 80% off\",\n",
        "            \"flash sale starting in 2 hours\", \"new collection, free shipping worldwide\",\n",
        "            \"best price guaranteed for early birds\", \"special discount coupon for first 100 buyers\",\n",
        "            \"reserve now and get extra 20% off\", \"only 3 items left, order now!\"\n",
        "        ]\n",
        "\n",
        "        lottery_phrases = [\n",
        "            \"congratulations! you’ve won a $1000 gift card\", \"you are selected to receive a free iPhone\",\n",
        "            \"claim your $500 Amazon voucher now\", \"winner! reply to confirm your prize\",\n",
        "            \"spin the wheel to win exciting gifts\", \"lucky draw winner – act fast\",\n",
        "            \"redeem your exclusive prize today\", \"final reminder: unclaimed reward waiting\",\n",
        "            \"instant gift unlocked, tap to get\", \"biggest jackpot giveaway this week\"\n",
        "        ]\n",
        "\n",
        "        scam_alert_phrases = [\n",
        "            \"your account will be suspended unless verified\", \"unusual login detected, reset password now\",\n",
        "            \"security update required immediately\", \"urgent: payment failed, update details now\",\n",
        "            \"verify your identity to avoid account closure\", \"your Netflix subscription is on hold, confirm payment\",\n",
        "            \"important: unauthorized activity detected\", \"bank alert: confirm transaction or account locked\",\n",
        "            \"last warning: confirm within 24 hours\", \"emergency: suspicious access blocked, verify\"\n",
        "        ]\n",
        "\n",
        "        call_to_action_phrases = [\n",
        "            \"click here to confirm\", \"reply YES to activate bonus\",\n",
        "            \"register before midnight and win\", \"tap now to claim your reward\",\n",
        "            \"sign up today, limited seats\", \"confirm immediately to proceed\",\n",
        "            \"act fast, offer expires soon\", \"verify email to continue\",\n",
        "            \"download the app and get free points\", \"complete payment within 12 hours\"\n",
        "        ]\n",
        "\n",
        "        social_engineering_phrases = [\n",
        "            \"hey grandma, i need $500 for hospital bills\", \"hi mom, send money asap, phone broke\",\n",
        "            \"boss asked me to buy 3 gift cards urgently\", \"john, can you transfer $300 now, emergency\",\n",
        "            \"it’s me, your cousin, stuck abroad, need help\", \"friend, please help me with $200 loan\",\n",
        "            \"hi, i lost my wallet, send $150 to this account\", \"urgent! i can’t talk now, send cash fast\",\n",
        "            \"help me pay this fine, will return tomorrow\", \"sister, please pay $400 for my surgery\"\n",
        "        ]\n",
        "\n",
        "        obfuscated_phrases = [\n",
        "            \"Cl!ck h3re t0 w1n fr€e iPh0ne\", \"G€t y0ur r3fund n0w!!!\",\n",
        "            \"L!mited 0ff3r: Fr33 $$$ r3ward\", \"C@shb@ck av@il@ble t0d@y\",\n",
        "            \"W!n b!g pr!ze, act f@st\", \"Cl@im y0ur 100% b0nus\",\n",
        "            \"Fr33 g!ft w!th 0rder\", \"Up t0 $5000 r3fund @pprov3d\",\n",
        "            \"R3ply N0W t0 r3c3ive $$$\", \"Urg3nt!!! C0nfirm d3tails 1mm3di@tely\"\n",
        "        ]\n",
        "\n",
        "        # Gom các nhóm vào 1 danh sách\n",
        "        spam_phrase_groups = [\n",
        "            financial_phrases, promotion_phrases, lottery_phrases,\n",
        "            scam_alert_phrases, call_to_action_phrases,\n",
        "            social_engineering_phrases, obfuscated_phrases\n",
        "        ]\n",
        "        return spam_phrase_groups\n",
        "\n",
        "    # Dùng cho cách 2 (có thể lấy từ LLM bên ngoài xịn hơn)\n",
        "    def _init_ham_phrases(self):\n",
        "        # Các cụm ham dễ gây hiểu nhầm\n",
        "        # ----- 7 nhóm cụm dễ gây hiểu nhầm thành spam (giống spam phrases) -----\n",
        "        financial_phrases = [\n",
        "            \"I got $100 cashback yesterday\", \"The bank refunded me $200 already\",\n",
        "            \"I earned $150/day last month from freelancing\", \"Approved for $500 loan finally\",\n",
        "            \"Got quick $300 refund after confirmation\", \"The store gave me $250 cashback\",\n",
        "            \"My account got $100 instantly after confirming\", \"I received instant $400 transfer today\",\n",
        "            \"They sent me exclusive $600 grant, lol\", \"Netflix actually gave me 3 months free\"\n",
        "        ]\n",
        "\n",
        "        promotion_phrases = [\n",
        "            \"I bought one and got one free, legit deal\", \"Flash sale 80% off, I already ordered\",\n",
        "            \"Exclusive deal worked for me, saved a lot\", \"Hot sale 2 hours ago, crazy cheap\",\n",
        "            \"New collection free shipping, I tried it\", \"Best price ever for members\",\n",
        "            \"Got special coupon, it worked!\", \"Reserved early and saved 20%\",\n",
        "            \"Only 3 items left when I bought mine\", \"Order now, it’s real not fake\"\n",
        "        ]\n",
        "\n",
        "        lottery_phrases = [\n",
        "            \"I actually won a $1000 voucher at the mall\", \"I got a free iPhone from the lucky draw\",\n",
        "            \"Claimed my $500 Amazon voucher legit\", \"Won a prize, just showed my ticket\",\n",
        "            \"Spun the wheel at the fair and got gifts\", \"Lucky draw worked for me today\",\n",
        "            \"Redeemed my exclusive prize at the shop\", \"They reminded me to collect my reward\",\n",
        "            \"Gift unlocked at the event, so fun\", \"Jackpot giveaway, real not scam\"\n",
        "        ]\n",
        "\n",
        "        scam_alert_phrases = [\n",
        "            \"I got unusual login alert, but it was me\", \"Reset my password after warning, fine now\",\n",
        "            \"Got security update mail, confirmed it’s real\", \"Payment failed once, updated and ok now\",\n",
        "            \"Had to verify identity, bank confirmed legit\", \"Netflix on hold but paid, no issue\",\n",
        "            \"Bank asked to confirm transaction, was me\", \"Warning mail yesterday, false alarm\",\n",
        "            \"Confirmed within 24h, all safe\", \"Suspicious access blocked, just me traveling\"\n",
        "        ]\n",
        "\n",
        "        call_to_action_phrases = [\n",
        "            \"I clicked to confirm and it worked\", \"Replied YES, bonus legit\",\n",
        "            \"Registered before midnight, no scam\", \"Tapped link, claimed reward legit\",\n",
        "            \"Signed up today, limited seat real\", \"Confirmed immediately, nothing shady\",\n",
        "            \"Acted fast, got discount legit\", \"Verified email, safe and done\",\n",
        "            \"Downloaded app, free points real\", \"Paid within 12 hours, successful\"\n",
        "        ]\n",
        "\n",
        "        social_engineering_phrases = [\n",
        "            \"Mom, don’t worry I sent you $500 hospital bill already\", \"Hi mom, phone broke but friend helped\",\n",
        "            \"Boss asked me to buy gift cards for office, already did\", \"John, I transferred $300, check it\",\n",
        "            \"Cousin stuck abroad, we sent help\", \"Friend lent me $200 last week, repaid\",\n",
        "            \"Lost wallet but someone returned $150\", \"Urgent cash request yesterday, sorted now\",\n",
        "            \"Helped pay fine, friend returned\", \"Sister’s surgery done, paid $400 legit\"\n",
        "        ]\n",
        "\n",
        "        obfuscated_phrases = [\n",
        "            \"Clicked h3re to win fr€e gift, real promo\", \"Got r3fund n0w!!! 100% legit\",\n",
        "            \"Fr33 reward worked, tried it\", \"C@shb@ck real, used today\",\n",
        "            \"Won prize real, not spam\", \"Cl@imed b0nus myself, safe\",\n",
        "            \"Gift order legit, no scam\", \"Refund approved @ bank, no issue\",\n",
        "            \"Replied N0W got $$$ legit\", \"Urg3nt confirm done, real bank\"\n",
        "        ]\n",
        "\n",
        "        hard_ham_phrase_groups = [\n",
        "            financial_phrases, promotion_phrases, lottery_phrases,\n",
        "            scam_alert_phrases, call_to_action_phrases,\n",
        "            social_engineering_phrases, obfuscated_phrases\n",
        "        ]\n",
        "        return hard_ham_phrase_groups\n",
        "\n",
        "    # Dùng cho cách 1\n",
        "    def generate_like_spam_ham(self, label='spam', n_per_group=10, api_key=None, model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", group=None):\n",
        "        \"\"\"\n",
        "        Sinh các câu spam/ham tinh vi mô phỏng người dùng, chia theo 7 nhóm phổ biến (70 câu total).\n",
        "\n",
        "        Args:\n",
        "            label (str): 'spam' hoặc 'ham'\n",
        "            n_per_group (int): số câu trên mỗi nhóm\n",
        "            api_key (str): Together.ai API key\n",
        "            model (str): Model ID (Mixtral, LLaMA3,...)\n",
        "            group (str or None): nếu chỉ muốn sinh 1 nhóm, chọn từ:\n",
        "                'financial', 'promotion', 'lottery', 'scam_alert',\n",
        "                'call_to_action', 'social_engineering', 'obfuscated'\n",
        "\n",
        "        Returns:\n",
        "            List[str]: Danh sách câu được sinh\n",
        "        \"\"\"\n",
        "        if api_key is None:\n",
        "            raise ValueError(\"❌ Cần cung cấp API key Together.ai.\")\n",
        "\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "        group_prompts = {\n",
        "            \"financial\": {\n",
        "                \"spam\": \"Generate realistic user-style spam messages that pretend to offer cashback, refunds, or financial rewards, but are actually deceptive.\",\n",
        "                \"ham\": \"Generate legitimate human messages that mention refunds, cashback, or money transfers in real-life, harmless contexts.\"\n",
        "            },\n",
        "            \"promotion\": {\n",
        "                \"spam\": \"Generate spammy messages that appear friendly but are disguised promotions, sales, or limited-time offers.\",\n",
        "                \"ham\": \"Generate genuine user messages that talk about real promotions or sales they used, sounding casual and truthful.\"\n",
        "            },\n",
        "            \"lottery\": {\n",
        "                \"spam\": \"Generate scam-like messages that claim the user won a lottery, prize, or giveaway — but in a deceptive, subtle tone.\",\n",
        "                \"ham\": \"Generate honest messages where users talk about actually winning something in real life — malls, fairs, etc.\"\n",
        "            },\n",
        "            \"scam_alert\": {\n",
        "                \"spam\": \"Generate deceptive user-style spam about account alerts, security warnings, or password issues to trick the recipient.\",\n",
        "                \"ham\": \"Generate real user messages where people talk about security alerts or login issues they experienced, in normal tone.\"\n",
        "            },\n",
        "            \"call_to_action\": {\n",
        "                \"spam\": \"Write spam messages with subtle calls to action like 'click here', 'register', or 'confirm' hidden in casual tone.\",\n",
        "                \"ham\": \"Write normal human messages that mention clicking links or confirming actions, but are not spam.\"\n",
        "            },\n",
        "            \"social_engineering\": {\n",
        "                \"spam\": \"Generate spam messages that use fake urgency or personal relationships (e.g., 'Mom', 'Boss', 'Friend') to request money.\",\n",
        "                \"ham\": \"Generate real messages from people who had real emergencies or money transfers, in personal tone.\"\n",
        "            },\n",
        "            \"obfuscated\": {\n",
        "                \"spam\": \"Write spam messages that use obfuscated text like '$$$', 'Fr33', 'Cl!ck', to bypass filters but sound human.\",\n",
        "                \"ham\": \"Write real human messages that coincidentally use symbols or strange formats, but are not spam.\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        selected_groups = [group] if group else list(group_prompts.keys())\n",
        "        all_outputs = []\n",
        "\n",
        "        for g in selected_groups:\n",
        "            system_prompt = group_prompts[g][label]\n",
        "            full_prompt = f\"{system_prompt}\\nGenerate {n_per_group} examples. Output only the messages, one per line.\"\n",
        "\n",
        "            payload = {\n",
        "                \"model\": model,\n",
        "                \"prompt\": full_prompt,\n",
        "                \"max_tokens\": 1000,\n",
        "                \"temperature\": 0.9,\n",
        "                \"top_p\": 0.95\n",
        "            }\n",
        "\n",
        "            print(f\"📡 Generating {label.upper()} – Group: {g} ...\")\n",
        "\n",
        "            response = requests.post(\"https://api.together.xyz/v1/completions\", headers=headers, json=payload)\n",
        "\n",
        "            if response.ok:\n",
        "                raw_output = response.json()[\"choices\"][0][\"text\"].strip()\n",
        "                lines = [line.strip(\"-•* \") for line in raw_output.splitlines() if line.strip()]\n",
        "                all_outputs.extend(lines)\n",
        "            else:\n",
        "                raise RuntimeError(f\"❌ API error @group {g}: {response.status_code} - {response.text}\")\n",
        "\n",
        "        return all_outputs\n",
        "\n",
        "    # Dùng cho cách 1\n",
        "    def load_llm_phrases(self, spam_list, ham_list, group_size=10):\n",
        "        \"\"\"\n",
        "        Từ danh sách 70 câu spam + 70 câu ham, chia thành 7 nhóm (mỗi nhóm 10 câu).\n",
        "        Dùng thay cho _init_spam_phrases() và _init_ham_phrases()\n",
        "\n",
        "        Args:\n",
        "            spam_list (list[str]): Danh sách 70 câu spam từ LLM\n",
        "            ham_list (list[str]): Danh sách 70 câu ham từ LLM\n",
        "            group_size (int): Số câu mỗi nhóm (mặc định 10)\n",
        "\n",
        "        Tác dụng:\n",
        "            Gán trực tiếp vào self.spam_groups và self.ham_groups\n",
        "        \"\"\"\n",
        "        #assert len(spam_list) == len(ham_list) == 70, \"❌ Cần đúng 70 câu mỗi loại để chia nhóm.\"\n",
        "        spam_list = spam_list[:70]\n",
        "        ham_list = ham_list[:70]\n",
        "        self.spam_groups = [spam_list[i:i+group_size] for i in range(0, 70, group_size)]\n",
        "        self.ham_groups = [ham_list[i:i+group_size] for i in range(0, 70, group_size)]\n",
        "        print(\"✅ Đã load 140 câu LLM và chia thành 7 nhóm spam/ham.\")\n",
        "        return self.spam_groups, self.ham_groups\n",
        "\n",
        "    def _generate_sentences(self, base_texts, phrase_groups, n):\n",
        "        results = []\n",
        "        for _ in range(n):\n",
        "            base = random.choice(base_texts)\n",
        "            insert = random.choice(random.choice(phrase_groups))\n",
        "            sentence = f\"{insert}. {base}\" if random.random() < 0.5 else f\"{base}, btw {insert}.\"\n",
        "            results.append(sentence)\n",
        "        return results\n",
        "\n",
        "    def generate_hard_spam(self, output_path=\"/content/hard_spam_generated_auto.csv\"):\n",
        "        num_ham = self.df[self.df[\"Category\"] == \"ham\"].shape[0]\n",
        "        num_spam = self.df[self.df[\"Category\"] == \"spam\"].shape[0]\n",
        "        if num_spam >= num_ham:\n",
        "            print(\"✅ Spam đã đủ, không sinh thêm.\")\n",
        "            return []\n",
        "        n_generate = int((num_ham - num_spam) * self.alpha_spam)\n",
        "        base_texts = self.df[self.df[\"Category\"] == \"ham\"][\"Message\"].sample(n=n_generate, random_state=42).tolist()\n",
        "        generated = self._generate_sentences(base_texts, self.spam_groups, n_generate)\n",
        "        pd.DataFrame({\"Category\": [\"spam\"] * n_generate, \"Message\": generated}).to_csv(output_path, index=False)\n",
        "        print(f\"✅ Sinh {n_generate} hard spam -> {output_path}\")\n",
        "        return generated\n",
        "\n",
        "    def generate_hard_ham(self, output_path=\"/content/hard_ham_generated_auto.csv\"):\n",
        "        num_ham = self.df[self.df[\"Category\"] == \"ham\"].shape[0]\n",
        "        num_spam = self.df[self.df[\"Category\"] == \"spam\"].shape[0]\n",
        "        if num_ham >= num_spam:\n",
        "            n_generate = int((num_ham - num_spam) * self.alpha_ham)\n",
        "            base_texts = self.df[self.df[\"Category\"] == \"ham\"][\"Message\"].sample(n=n_generate, random_state=42).tolist()\n",
        "            generated = self._generate_sentences(base_texts, self.ham_groups, n_generate)\n",
        "            pd.DataFrame({\"Category\": [\"ham\"] * n_generate, \"Message\": generated}).to_csv(output_path, index=False)\n",
        "            print(f\"✅ Sinh {n_generate} hard ham -> {output_path}\")\n",
        "            return generated\n",
        "        else:\n",
        "            print(\"✅ Ham đã đủ, không cần sinh thêm.\")\n",
        "            return []\n",
        "\n",
        "    def generate_synonym_replacement(self, messages, labels, aug_ratio=0.2):\n",
        "        MAX_AUG = int(len(messages) * aug_ratio)\n",
        "        augmented_messages, augmented_labels = [], []\n",
        "        print(f\"✅ Synonym Replacement: sinh tối đa {MAX_AUG} câu.\")\n",
        "        for msg, label in zip(messages, labels):\n",
        "            if len(augmented_messages) >= MAX_AUG:\n",
        "                break\n",
        "            if random.random() > 0.8:\n",
        "                aug_msg = self.synonym_replacement(msg)\n",
        "                if aug_msg != msg:\n",
        "                    augmented_messages.append(aug_msg)\n",
        "                    augmented_labels.append(label)\n",
        "        print(f\"✅ Đã sinh {len(augmented_messages)} câu augmented thực tế.\")\n",
        "        return augmented_messages, augmented_labels\n",
        "\n",
        "    def synonym_replacement(self, text, n=1):\n",
        "        words = text.split()\n",
        "        new_words = words.copy()\n",
        "        candidates = [w for w in words if wordnet.synsets(w)]\n",
        "        if not candidates:\n",
        "            return text\n",
        "        random.shuffle(candidates)\n",
        "        replaced_count = 0\n",
        "        for random_word in candidates:\n",
        "            synonyms = wordnet.synsets(random_word)\n",
        "            if synonyms:\n",
        "                synonym = synonyms[0].lemmas()[0].name().replace('_', ' ')\n",
        "                if synonym.lower() != random_word.lower():\n",
        "                    new_words = [synonym if w == random_word else w for w in new_words]\n",
        "                    replaced_count += 1\n",
        "            if replaced_count >= n:\n",
        "                break\n",
        "        return \" \".join(new_words)\n",
        "\n",
        "    # Tự động sinh test case\n",
        "    def generate_user_like_spam_ham(self, label='spam', n=10, api_key=None, model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"):\n",
        "        \"\"\"\n",
        "        Sinh ra các câu spam/ham giống như tin nhắn từ người dùng thật có nội dung hỏi hoặc trò chuyện.\n",
        "\n",
        "        Args:\n",
        "            label (str): 'spam' hoặc 'ham'.\n",
        "            n (int): Số lượng cần sinh.\n",
        "            api_key (str): Together.ai API key.\n",
        "            model (str): Model ID (Mixtral/Mistral/LLaMA3...)\n",
        "\n",
        "        Returns:\n",
        "            List[str]: Danh sách tin nhắn được sinh ra.\n",
        "        \"\"\"\n",
        "        import requests\n",
        "\n",
        "        if api_key is None:\n",
        "            raise ValueError(\"❌ Bạn cần cung cấp Together.ai API key.\")\n",
        "\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "        prompt_template = {\n",
        "            \"spam\": (\n",
        "                \"You are writing deceptive user messages that look like innocent questions, but are actually subtle spam.\\n\"\n",
        "                \"Generate realistic user messages (in casual style) that include spam signals, but sound like real human questions or messages.\\n\"\n",
        "                f\"Generate {n} such examples. Output only the messages, one per line.\"\n",
        "            ),\n",
        "            \"ham\": (\n",
        "                \"You are writing user messages that look like spam at first, but are actually legitimate, honest messages.\\n\"\n",
        "                \"Generate realistic messages where a user might mention cashback, refund, login alerts, etc. but in a real, harmless context.\\n\"\n",
        "                f\"Generate {n} such examples. Output only the messages, one per line.\"\n",
        "            )\n",
        "        }\n",
        "\n",
        "        prompt = prompt_template[label]\n",
        "\n",
        "        payload = {\n",
        "            \"model\": model,\n",
        "            \"prompt\": prompt,\n",
        "            \"max_tokens\": 1000,\n",
        "            \"temperature\": 0.9,\n",
        "            \"top_p\": 0.95,\n",
        "            \"stop\": None\n",
        "        }\n",
        "\n",
        "        response = requests.post(\"https://api.together.xyz/v1/completions\", headers=headers, json=payload)\n",
        "\n",
        "        if response.ok:\n",
        "            raw_output = response.json()[\"choices\"][0][\"text\"].strip()\n",
        "            # Tách các dòng nếu có xuống dòng\n",
        "            return [line.strip(\"-•* \") for line in raw_output.splitlines() if line.strip()]\n",
        "        else:\n",
        "            raise RuntimeError(f\"Lỗi khi gọi Together API: {response.status_code} - {response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k43QgLT2eztA"
      },
      "source": [
        "## Import kaggle dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sKFnaD_V7hkj"
      },
      "outputs": [],
      "source": [
        "def load_data_from_kaggle():\n",
        "    \"\"\"Load Vietnamese spam dataset from Kaggle\"\"\"\n",
        "    df = kagglehub.load_dataset(\n",
        "        KaggleDatasetAdapter.PANDAS,\n",
        "        \"victorhoward2/vietnamese-spam-post-in-social-network\",\n",
        "        \"vi_dataset.csv\"\n",
        "    )\n",
        "    print(f\"Successfully loaded Kaggle dataset with {len(df)} records\")\n",
        "    print(\"First 5 records:\")\n",
        "    print(df.head())\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccv9mbudl8W-"
      },
      "source": [
        "## Import google drive (bản mới)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fuKNamlZlzvc"
      },
      "outputs": [],
      "source": [
        "def load_data_from_gdrive():\n",
        "\n",
        "    # 1. Download file từ GDrive\n",
        "    !gdown --id 1N7rk-kfnDFIGMeX0ROVTjKh71gcgx-7R\n",
        "    DATASET_PATH = '/content/2cls_spam_text_cls.csv'\n",
        "\n",
        "    # 2. Load dataset gốc\n",
        "    df_base = pd.read_csv(DATASET_PATH)\n",
        "    print(\"First 5 records:\")\n",
        "    print(df_base.head())\n",
        "\n",
        "    return df_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toPKkX5oZc3B"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SOpu2F7n7zmA"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataframe(df):\n",
        "    \"\"\"Preprocess the loaded dataframe to extract messages and labels\"\"\"\n",
        "    print(\"Preprocessing dataframe...\")\n",
        "    print(f\"Columns available: {list(df.columns)}\")\n",
        "\n",
        "    # Try to identify text and label columns\n",
        "    text_column = None\n",
        "    label_column = None\n",
        "\n",
        "    # Common text column names\n",
        "    text_candidates = ['message', 'text', 'content', 'email', 'post', 'comment', \"texts_vi\"]\n",
        "    for col in df.columns:\n",
        "        if col.lower() in text_candidates or 'text' in col.lower() or 'message' in col.lower():\n",
        "            text_column = col\n",
        "            break\n",
        "\n",
        "    # Common label column names\n",
        "    label_candidates = ['label', 'class', 'category', 'type']\n",
        "    for col in df.columns:\n",
        "        if col.lower() in label_candidates or 'label' in col.lower():\n",
        "            label_column = col\n",
        "            break\n",
        "\n",
        "    # If not found, use first two columns\n",
        "    if text_column is None:\n",
        "        text_column = df.columns[0]\n",
        "        print(f\"Text column not found, using first column: {text_column}\")\n",
        "\n",
        "    if label_column is None:\n",
        "        label_column = df.columns[1] if len(df.columns) > 1 else df.columns[0]\n",
        "        print(f\"Label column not found, using: {label_column}\")\n",
        "\n",
        "    print(f\"Using text column: {text_column}\")\n",
        "    print(f\"Using label column: {label_column}\")\n",
        "\n",
        "    # Clean text data\n",
        "    df[text_column] = df[text_column].astype(str).fillna('')\n",
        "    df = df[df[text_column].str.strip() != '']  # Remove empty texts\n",
        "\n",
        "    # Clean labels - convert to ham/spam format\n",
        "    df[label_column] = df[label_column].astype(str).str.lower()\n",
        "\n",
        "    # Map various label formats to ham/spam\n",
        "    label_mapping = {\n",
        "        '0': 'ham', '1': 'spam',\n",
        "        'ham': 'ham', 'spam': 'spam',\n",
        "        'normal': 'ham', 'spam': 'spam',\n",
        "        'legitimate': 'ham', 'phishing': 'spam',\n",
        "        'not_spam': 'ham', 'is_spam': 'spam'\n",
        "    }\n",
        "\n",
        "    df[label_column] = df[label_column].map(label_mapping).fillna(df[label_column])\n",
        "\n",
        "    # Show label distribution\n",
        "    label_counts = df[label_column].value_counts()\n",
        "    print(f\"Label distribution:\")\n",
        "    for label, count in label_counts.items():\n",
        "        print(f\"  {label}: {count} samples\")\n",
        "\n",
        "    messages = df[text_column].tolist()\n",
        "    labels = df[label_column].tolist()\n",
        "\n",
        "    print(f\"Processed {len(messages)} messages\")\n",
        "    return messages, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyeuBEiV71d6"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pyQ_rTLK72rl"
      },
      "outputs": [],
      "source": [
        "def load_dataset(source='kaggle', file_id=None):\n",
        "    if source == 'kaggle':\n",
        "        df = load_data_from_kaggle()\n",
        "    elif source == 'gdrive':\n",
        "        # if file_id is None:\n",
        "        #     file_id = \"1N7rk-kfnDFIGMeX0ROVTjKh71gcgx-7R\"  # Default ID\n",
        "        df = load_data_from_gdrive()\n",
        "    else:\n",
        "        raise ValueError(\"Source must be 'kaggle' or 'gdrive'\")\n",
        "\n",
        "    if df is None:\n",
        "        raise Exception(f\"Failed to load data from {source}\")\n",
        "\n",
        "    messages, labels = preprocess_dataframe(df)\n",
        "    return messages, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eadqgADs78LK"
      },
      "source": [
        "## Embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942,
          "referenced_widgets": [
            "77fdaa5853dc444b91bf43b59edd825c",
            "70dad4b0096e4c6dbe9a04871ebdce4b",
            "0c8d4b1662204eef87643c307eaa9ed2",
            "8b436dcd9dc44f9e9021f6c3c35cafd7",
            "d64a5b0e016540a48b0cbba21dbfa656",
            "865074dd95e84e1c97e38b5078bddbfe",
            "0167b157231b4dceb946ed2729b9cf8c",
            "6a636cde9125456c8018d8852272fcfc",
            "1014794fd0194aacbe7656a336536237",
            "9cfcbf51d9b44b9a9cec3aeb075b8490",
            "95b82a2d5ef1437d939bd5c060c45455",
            "019bf3423ae24597a42e55e6f59e7138",
            "7610cbb6922b49e7bfb8409a22132d8f",
            "ef4792efbe1a4aacbd27eecb4e194d83",
            "c87e66e252e64007b67d1f316093647a",
            "70f1fa4841304eaa9317eca3ceafbf08",
            "5dfe0811eded42939ff30f2f9289e9f0",
            "3729e4aaa49b4f21b8f64f5a76845a5f",
            "e1d51c03e323415594403af0ad54e11a",
            "d8e03c868d214f37854a641c2e9e8d9d",
            "29588c59102d406f8bace65fc8185279",
            "afc5aa094a104c3385ceadabf7146f0a",
            "36acabaf71e447d3a0fba27d9bbfe3f5",
            "3302260d5d0845f6adf34cc271961404",
            "98c5fcba5b754a8fa7811dda80cf9bac",
            "782061da906e41578cd4cf726ec35dd6",
            "e9b2d7efce564afc8479194a277841cd",
            "b8293d136ae84fb58f74603ea7769bd4",
            "9ccf886b765e4bfabdc77af7dc9f9b23",
            "d57d4f52940f480e95724ca6190863e1",
            "d0959f37ffcf44e1b6ceb1422909fdc5",
            "a7e355973f30452e921038a93929cf03",
            "fff71ab1439142dba67b1a70e9441182",
            "cedadc9bd4bf4db5a32b65f2b9c9f064",
            "604cb193401249a2b5b75399fb652e00",
            "cd7a46d1cdd848e2a1edee1fb10f2c74",
            "f5e7816826084cfe86e73c63ebf24060",
            "a879b09cb58b40f9a4dd34fb571ef982",
            "fb06157d50874e949248b2dd57078e79",
            "6aa51a096ff34198b7cb136863d31373",
            "450e743b06524243ae6373a8c3a1f9ad",
            "8aa92263ef3247f8a340a066859d52c0",
            "2c5e523eca5e412eade789ebadbd0c88",
            "383f74f83f1e4016a3a63e2b6b996e2c",
            "88e2b54b3afe4833b24ebbfd40c30b78",
            "0879f38663314487bf9dbec24fb1cf38",
            "1c086427b425430e8e2de80d291037bc",
            "14aa3171cb1847adab5be8b2ff36c69d",
            "df3a97903d0048dd918611e0a246edb5",
            "8605b8cf73b64ab8927b67c27ff76ab1",
            "08ef224a00974f61841917923e214a0f",
            "755d7a5f8a63489788e7ee762ca0371d",
            "022f3650c8654b4997f081f932075f38",
            "60f6d1a3686141fabacd6939c5efad1d",
            "55d578a48e3a47218f53008d46fa6e84",
            "35875c4539c641579752e56ee9fc5a27",
            "cbc1f06dbf214c31af5bb104cb79c820",
            "6e7889ce4c37453d8fa2a8758a3888ec",
            "e56d6e694628400dbfe79f7bfbecac43",
            "1d8e05fc52dd433398deb92d412253e4",
            "ad5ddd62d4a243b59c1e306936b5e502",
            "9d06e8c002e84f45982d8ffc0abf184b",
            "376d883743364ba6876bf72f1a7c455b",
            "7502c94c5b1947efa3ae526bac9e2019",
            "f2ef3a9a3baa4125aafdac9a1492962d",
            "7a0c4dbb7950486aad0802ae62160eae"
          ]
        },
        "id": "vN9yJnLB8AVi",
        "outputId": "cf9f7b2f-451a-46f6-ad88-ede54b491a2f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77fdaa5853dc444b91bf43b59edd825c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "019bf3423ae24597a42e55e6f59e7138",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36acabaf71e447d3a0fba27d9bbfe3f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cedadc9bd4bf4db5a32b65f2b9c9f064",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88e2b54b3afe4833b24ebbfd40c30b78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35875c4539c641579752e56ee9fc5a27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "XLMRobertaModel(\n",
              "  (embeddings): XLMRobertaEmbeddings(\n",
              "    (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "    (token_type_embeddings): Embedding(1, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): XLMRobertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x XLMRobertaLayer(\n",
              "        (attention): XLMRobertaAttention(\n",
              "          (self): XLMRobertaSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): XLMRobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): XLMRobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): XLMRobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): XLMRobertaPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_name = \"intfloat/multilingual-e5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "59IiB9hL8B0N"
      },
      "outputs": [],
      "source": [
        "def average_pool(last_hidden_states, attention_mask):\n",
        "    last_hidden = last_hidden_states.masked_fill(\n",
        "        ~attention_mask[..., None].bool(), 0.0\n",
        "    )\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XvboTOSb8Ghu"
      },
      "outputs": [],
      "source": [
        "def get_embeddings(texts, model, tokenizer, device, batch_size=32):\n",
        "    embeddings = []\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating embeddings\"):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "\n",
        "        batch_texts_with_prefix = [f\"passage: {text}\" for text in batch_texts]\n",
        "        batch_dict = tokenizer(batch_texts_with_prefix, max_length=512, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        batch_dict = {k: v.to(device) for k, v in batch_dict.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch_dict)\n",
        "            batch_embeddings = average_pool(outputs.last_hidden_state, batch_dict[\"attention_mask\"])\n",
        "            batch_embeddings = F.normalize(batch_embeddings, p=2, dim=1)\n",
        "            embeddings.append(batch_embeddings.cpu().numpy())\n",
        "\n",
        "    return np.vstack(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydI6ukpn8Jcm"
      },
      "source": [
        "## Handle imblance label data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vFuSGpcL8OCi"
      },
      "outputs": [],
      "source": [
        "def calculate_class_weights(labels):\n",
        "    \"\"\"Calculate class weights for handling imbalanced data\"\"\"\n",
        "    label_counts = Counter(labels)\n",
        "    total_samples = len(labels)\n",
        "    num_classes = len(label_counts)\n",
        "\n",
        "    class_weights = {}\n",
        "    for label, count in label_counts.items():\n",
        "        # Inverse frequency weighting\n",
        "        class_weights[label] = total_samples / (num_classes * count)\n",
        "\n",
        "    print(\"Class distribution:\")\n",
        "    for label, count in label_counts.items():\n",
        "        print(f\"  {label}: {count} samples (weight: {class_weights[label]:.3f})\")\n",
        "\n",
        "    return class_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vi-QPsl8P-G"
      },
      "source": [
        "## Compute saliency scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qWFlOjDg8WxM"
      },
      "outputs": [],
      "source": [
        "def compute_saliency_scores(query_text, model, tokenizer, device, index, train_metadata, k=10):\n",
        "    \"\"\"Compute saliency scores for explainability\"\"\"\n",
        "    tokens = tokenizer.tokenize(query_text)\n",
        "\n",
        "    if len(tokens) <= 1:\n",
        "        return np.array([1.0])\n",
        "\n",
        "    # Get original embedding and spam score\n",
        "    query_with_prefix = f\"query: {query_text}\"\n",
        "    batch_dict = tokenizer([query_with_prefix], max_length=512, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    batch_dict = {k: v.to(device) for k, v in batch_dict.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch_dict)\n",
        "        original_embedding = average_pool(outputs.last_hidden_state, batch_dict[\"attention_mask\"])\n",
        "        original_embedding = F.normalize(original_embedding, p=2, dim=1)\n",
        "        original_embedding = original_embedding.cpu().numpy().astype(\"float32\")\n",
        "\n",
        "    original_scores, original_indices = index.search(original_embedding, k)\n",
        "    original_spam_score = sum(s for s, idx in zip(original_scores[0], original_indices[0])\n",
        "                             if train_metadata[idx][\"label\"] == \"spam\")\n",
        "\n",
        "    saliencies = []\n",
        "\n",
        "    # Compute saliency for each token\n",
        "    for i, token in enumerate(tokens):\n",
        "        token_mask = tokens.copy()\n",
        "        token_mask[i] = tokenizer.pad_token\n",
        "        masked_text = tokenizer.convert_tokens_to_string(token_mask)\n",
        "\n",
        "        masked_query = f\"query: {masked_text}\"\n",
        "        masked_batch_dict = tokenizer([masked_query], max_length=512, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        masked_batch_dict = {k: v.to(device) for k, v in masked_batch_dict.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**masked_batch_dict)\n",
        "            masked_embedding = average_pool(outputs.last_hidden_state, masked_batch_dict[\"attention_mask\"])\n",
        "            masked_embedding = F.normalize(masked_embedding, p=2, dim=1)\n",
        "            masked_embedding = masked_embedding.cpu().numpy().astype(\"float32\")\n",
        "\n",
        "        masked_scores, masked_indices = index.search(masked_embedding, k)\n",
        "        masked_spam_score = sum(s for s, idx in zip(masked_scores[0], masked_indices[0])\n",
        "                               if train_metadata[idx][\"label\"] == \"spam\")\n",
        "\n",
        "        saliency = original_spam_score - masked_spam_score\n",
        "        saliencies.append(saliency)\n",
        "\n",
        "    # Normalize saliencies\n",
        "    arr = np.array(saliencies)\n",
        "    if len(arr) > 1:\n",
        "        arr = (arr - arr.min()) / (np.ptp(arr) + 1e-12)\n",
        "    else:\n",
        "        arr = np.array([1.0])\n",
        "\n",
        "    return arr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-gUpbCg8X7Q"
      },
      "source": [
        "## Classification with KNN with weighted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5YtNQYEf8gKb"
      },
      "outputs": [],
      "source": [
        "def classify_with_weighted_knn(query_text, model, tokenizer, device, index, train_metadata, class_weights, k=10, alpha=0.5, explain=False):\n",
        "    \"\"\"Enhanced KNN classification with custom weighting formula\"\"\"\n",
        "\n",
        "    # Get query embedding\n",
        "    query_with_prefix = f\"query: {query_text}\"\n",
        "    batch_dict = tokenizer([query_with_prefix], max_length=512, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    batch_dict = {k: v.to(device) for k, v in batch_dict.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch_dict)\n",
        "        query_embedding = average_pool(outputs.last_hidden_state, batch_dict[\"attention_mask\"])\n",
        "        query_embedding = F.normalize(query_embedding, p=2, dim=1)\n",
        "        query_embedding = query_embedding.cpu().numpy().astype(\"float32\")\n",
        "\n",
        "    # Get nearest neighbors\n",
        "    scores, indices = index.search(query_embedding, k)\n",
        "\n",
        "    # Compute saliency weight\n",
        "    if explain:\n",
        "        saliency_scores = compute_saliency_scores(query_text, model, tokenizer, device, index, train_metadata, k)\n",
        "        saliency_weight = np.mean(saliency_scores)\n",
        "        tokens = tokenizer.tokenize(query_text)\n",
        "    else:\n",
        "        # Quick saliency approximation\n",
        "        saliency_weight = compute_quick_saliency(query_text)\n",
        "        saliency_scores = None\n",
        "        tokens = None\n",
        "\n",
        "    # Calculate weighted votes\n",
        "    vote_scores = {\"ham\": 0.0, \"spam\": 0.0}\n",
        "    neighbor_info = []\n",
        "\n",
        "    for i in range(k):\n",
        "        neighbor_idx = indices[0][i]\n",
        "        similarity = float(scores[0][i])\n",
        "        neighbor_label = train_metadata[neighbor_idx][\"label\"]\n",
        "        neighbor_message = train_metadata[neighbor_idx][\"message\"]\n",
        "\n",
        "        # Apply custom weighting formula: w = (1-α)×similarity×class_weight + α×saliency_weight\n",
        "        weight = (1 - alpha) * similarity * class_weights[neighbor_label] + alpha * saliency_weight\n",
        "\n",
        "        vote_scores[neighbor_label] += weight\n",
        "\n",
        "        neighbor_info.append({\n",
        "            \"score\": similarity,\n",
        "            \"weight\": weight,\n",
        "            \"label\": neighbor_label,\n",
        "            \"message\": neighbor_message[:100] + \"...\" if len(neighbor_message) > 100 else neighbor_message\n",
        "        })\n",
        "\n",
        "    # Get prediction\n",
        "    predicted_label = max(vote_scores, key=vote_scores.get)\n",
        "\n",
        "    result = {\n",
        "        \"prediction\": predicted_label,\n",
        "        \"vote_scores\": vote_scores,\n",
        "        \"neighbors\": neighbor_info,\n",
        "        \"saliency_weight\": saliency_weight,\n",
        "        \"alpha\": alpha\n",
        "    }\n",
        "\n",
        "    if explain:\n",
        "        result[\"tokens\"] = tokens\n",
        "        result[\"saliency_scores\"] = saliency_scores\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "29GvuwMV8ip1"
      },
      "outputs": [],
      "source": [
        "def compute_quick_saliency(text):\n",
        "    \"\"\"Enhanced saliency computation for subtle spam detection\"\"\"\n",
        "    words = text.lower().split()\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    basic_spam_keywords = [\n",
        "        'free', 'click', 'urgent', 'limited', 'offer', 'discount', 'sale', 'win', 'prize',\n",
        "        'money', 'cash', 'earn', 'guaranteed', 'act now', 'call now', 'congratulations',\n",
        "        'miễn phí', 'khuyến mãi', 'giảm giá', 'ưu đãi', 'thắng', 'giải thưởng', 'tiền',\n",
        "        'kiếm tiền', 'đảm bảo', 'hành động ngay', 'chúc mừng', 'cơ hội', 'quà tặng'\n",
        "    ]\n",
        "\n",
        "    social_engineering_keywords = [\n",
        "        'mom', 'boss', 'hr', 'manager', 'security update', 'unusual login',\n",
        "        'hospital bill', 'emergency', 'help buy', 'reimburse', 'gift cards',\n",
        "        'short-staffed', 'extra shifts', 'card was declined', 'warranty',\n",
        "        'mẹ', 'sếp', 'nhân sự', 'cập nhật bảo mật', 'đăng nhập bất thường',\n",
        "        'viện phí', 'khẩn cấp', 'giúp mua', 'hoàn tiền'\n",
        "    ]\n",
        "\n",
        "    urgency_patterns = [\n",
        "        'today', 'tomorrow', 'this week', 'before friday', 'reply yes',\n",
        "        'cancel anytime', 'confirm before', 'register early', 'already got mine',\n",
        "        'hôm nay', 'ngày mai', 'tuần này', 'trước thứ sáu', 'trả lời có'\n",
        "    ]\n",
        "\n",
        "    money_patterns = [\n",
        "        r'\\$\\d+', r'\\d+\\$', r'\\d+\\s*dollar', r'\\d+\\s*usd',\n",
        "        r'\\d+\\s*triệu', r'\\d+\\s*nghìn', r'\\d+\\s*đồng'\n",
        "    ]\n",
        "\n",
        "    suspicious_contexts = [\n",
        "        'just signed up', 'they refund', 'i already got', 'you should try',\n",
        "        'can you help', 'reply if', 'book a slot', 'free diagnostics',\n",
        "        'vừa đăng ký', 'họ hoàn tiền', 'tôi đã nhận', 'bạn nên thử'\n",
        "    ]\n",
        "\n",
        "    # Calculate scores\n",
        "    basic_spam_score = sum(1 for word in words if any(keyword in word for keyword in basic_spam_keywords))\n",
        "    social_eng_score = sum(2 for keyword in social_engineering_keywords if keyword in text_lower)  # Higher weight\n",
        "    urgency_score = sum(1.5 for pattern in urgency_patterns if pattern in text_lower)\n",
        "\n",
        "    # Money pattern detection (regex)\n",
        "    import re\n",
        "    money_score = 0\n",
        "    for pattern in money_patterns:\n",
        "        if re.search(pattern, text_lower):\n",
        "            money_score += 2  # High weight for money mentions\n",
        "\n",
        "    suspicious_score = sum(1.5 for context in suspicious_contexts if context in text_lower)\n",
        "\n",
        "    length_factor = 1.0\n",
        "    if len(words) < 5:  # Very short\n",
        "        length_factor = 0.8\n",
        "    elif len(words) > 50:  # Very long\n",
        "        length_factor = 1.2\n",
        "\n",
        "    # Combined saliency score\n",
        "    total_score = (basic_spam_score + social_eng_score + urgency_score + money_score + suspicious_score) * length_factor\n",
        "\n",
        "    # Normalize by text length but with minimum threshold\n",
        "    saliency = min(1.0, max(0.1, total_score / max(len(words), 1) + 0.2))\n",
        "\n",
        "    return saliency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpLrUAVE8kNx"
      },
      "source": [
        "## Find the best alpha in weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8UAQmhj18oQb"
      },
      "outputs": [],
      "source": [
        "def optimize_alpha_parameter(test_embeddings, test_labels, test_metadata, index, train_metadata, class_weights, k=10):\n",
        "    \"\"\"Find optimal alpha value for best accuracy\"\"\"\n",
        "    print(\"Optimizing alpha parameter...\")\n",
        "\n",
        "    alpha_values = np.arange(0.0, 1.1, 0.1)\n",
        "    best_alpha = 0.0\n",
        "    best_accuracy = 0.0\n",
        "    alpha_results = []\n",
        "\n",
        "    for alpha in tqdm(alpha_values, desc=\"Testing alpha values\"):\n",
        "        correct = 0\n",
        "        total = len(test_embeddings)\n",
        "\n",
        "        for i in range(total):\n",
        "            query_embedding = test_embeddings[i:i+1].astype(\"float32\")\n",
        "            true_label = test_metadata[i][\"label\"]\n",
        "            query_text = test_metadata[i][\"message\"]\n",
        "\n",
        "            # Use weighted classification\n",
        "            result = classify_with_weighted_knn(\n",
        "                query_text, model, tokenizer, device, index, train_metadata,\n",
        "                class_weights, k=k, alpha=alpha, explain=False\n",
        "            )\n",
        "\n",
        "            if result[\"prediction\"] == true_label:\n",
        "                correct += 1\n",
        "\n",
        "        accuracy = correct / total\n",
        "        alpha_results.append((alpha, accuracy))\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_alpha = alpha\n",
        "\n",
        "        print(f\"Alpha: {alpha:.1f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    print(f\"\\nBest alpha: {best_alpha:.1f} with accuracy: {best_accuracy:.4f}\")\n",
        "    return best_alpha, alpha_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmQBC6I78pLX"
      },
      "source": [
        "## Classify sub-category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Skm7DABKGSdn"
      },
      "outputs": [],
      "source": [
        "def classify_spam_subcategory(spam_texts, model, tokenizer, device):\n",
        "    \"\"\"Combine BERT embeddings with keyword matching\"\"\"\n",
        "    if not spam_texts:\n",
        "        return []\n",
        "\n",
        "    # 1. BERT embeddings\n",
        "    spam_embeddings = get_embeddings(spam_texts, model, tokenizer, device)\n",
        "\n",
        "    # 2. Category reference embeddings\n",
        "    reference_texts = {\n",
        "        'spam_quangcao': {\n",
        "            'vietnamese': \"khuyến mãi giảm giá sale ưu đãi mua ngay giá rẻ miễn phí quà tặng voucher coupon giải thưởng trúng thưởng cơ hội trúng\",\n",
        "            'english': \"promotional discount sale offer prize win money gift free deal bargain cheap special limited\",\n",
        "            'combined': \"khuyến mãi giảm giá promotional discount sale ưu đãi offer prize win quà tặng gift free voucher coupon deal bargain trúng thưởng\"\n",
        "        },\n",
        "        'spam_hethong': {\n",
        "            'vietnamese': \"thông báo cảnh báo tài khoản bảo mật xác nhận cập nhật hệ thống đăng nhập mật khẩu bị khóa hết hạn gia hạn\",\n",
        "            'english': \"notification alert account security confirm update system login password locked expired renewal verify suspended warning\",\n",
        "            'combined': \"thông báo notification cảnh báo alert tài khoản account bảo mật security xác nhận confirm cập nhật update hệ thống system đăng nhập login mật khẩu password\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    reference_embeddings = {}\n",
        "    for category, ref_text in reference_texts.items():\n",
        "        ref_emb = get_embeddings([ref_text], model, tokenizer, device)[0]\n",
        "        reference_embeddings[category] = ref_emb\n",
        "\n",
        "    subcategories = []\n",
        "\n",
        "    for i, (text, text_embedding) in enumerate(zip(spam_texts, spam_embeddings)):\n",
        "        # A. BERT semantic similarity\n",
        "        bert_scores = {}\n",
        "        for category, ref_emb in reference_embeddings.items():\n",
        "            similarity = np.dot(text_embedding, ref_emb) / (\n",
        "                np.linalg.norm(text_embedding) * np.linalg.norm(ref_emb)\n",
        "            )\n",
        "            bert_scores[category] = similarity\n",
        "\n",
        "        # B. Keyword matching (existing logic)\n",
        "        keyword_scores = {}\n",
        "        text_lower = text.lower()\n",
        "        category_keywords = {\n",
        "        'spam_quangcao': [\n",
        "            # Vietnamese advertising keywords\n",
        "            'khuyến mãi', 'giảm giá', 'sale', 'ưu đãi', 'mua ngay', 'giá rẻ', 'miễn phí',\n",
        "            'quà tặng', 'voucher', 'coupon', 'giải thưởng', 'trúng thưởng', 'cơ hội', 'trúng',\n",
        "            # English advertising keywords\n",
        "            'discount', 'sale', 'offer', 'promotion', 'free', 'deal', 'buy now', 'limited time',\n",
        "            'special offer', 'bargain', 'cheap', 'save money', 'win', 'prize', 'gift', 'won',\n",
        "            'congratulations', 'claim', 'click here', '$', 'money', 'cash'\n",
        "        ],\n",
        "        'spam_hethong': [\n",
        "            # Vietnamese system keywords\n",
        "            'thông báo', 'cảnh báo', 'tài khoản', 'bảo mật', 'xác nhận', 'cập nhật',\n",
        "            'hệ thống', 'đăng nhập', 'mật khẩu', 'bị khóa', 'hết hạn', 'gia hạn', 'khóa',\n",
        "            # English system keywords\n",
        "            'notification', 'alert', 'account', 'security', 'confirm', 'update',\n",
        "            'system', 'login', 'password', 'locked', 'expired', 'renewal', 'verify',\n",
        "            'suspended', 'warning', 'breach', 'urgent', 'immediately'\n",
        "        ]\n",
        "        }\n",
        "\n",
        "        for category, keywords in category_keywords.items():\n",
        "            score = sum(1 for keyword in keywords if keyword in text_lower)\n",
        "            keyword_scores[category] = score / len(keywords)  # Normalize\n",
        "\n",
        "        # C. Combine scores (weighted)\n",
        "        final_scores = {}\n",
        "        for category in bert_scores.keys():\n",
        "            # 70% BERT, 30% keywords\n",
        "            final_scores[category] = 0.7 * bert_scores[category] + 0.3 * keyword_scores[category]\n",
        "\n",
        "        # D. Choose best category\n",
        "        if max(final_scores.values()) < 0.3:  # Low confidence\n",
        "            best_category = 'spam_khac'\n",
        "        else:\n",
        "            best_category = max(final_scores, key=final_scores.get)\n",
        "\n",
        "        subcategories.append(best_category)\n",
        "\n",
        "        # Chỗ này thêm vào để log hả ???\n",
        "        # print(f\"Text: {text[:50]}...\")\n",
        "        # print(f\"BERT scores: {bert_scores}\")\n",
        "        # print(f\"Keyword scores: {keyword_scores}\")\n",
        "        # print(f\"Final: {best_category}\")\n",
        "\n",
        "    return subcategories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEF558W68vcf"
      },
      "source": [
        "## Đánh giá model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "z7gEyI5Q8z4_"
      },
      "outputs": [],
      "source": [
        "def evaluate_weighted_knn_accuracy(test_embeddings, test_labels, test_metadata, index, train_metadata, class_weights, alpha, k_values=[1, 3, 5]):\n",
        "    \"\"\"Evaluate accuracy using weighted KNN classification\"\"\"\n",
        "    results = {}\n",
        "    all_errors = {}\n",
        "\n",
        "    for k in k_values:\n",
        "        print(f\"\\nEvaluating with k={k}, alpha={alpha:.1f}\")\n",
        "        correct = 0\n",
        "        total = len(test_embeddings)\n",
        "        errors = []\n",
        "\n",
        "        for i in tqdm(range(total), desc=f\"Evaluating k={k}\"):\n",
        "            query_text = test_metadata[i][\"message\"]\n",
        "            true_label = test_metadata[i][\"label\"]\n",
        "\n",
        "            # Use weighted classification\n",
        "            result = classify_with_weighted_knn(\n",
        "                query_text, model, tokenizer, device, index, train_metadata,\n",
        "                class_weights, k=k, alpha=alpha, explain=False\n",
        "            )\n",
        "\n",
        "            predicted_label = result[\"prediction\"]\n",
        "\n",
        "            if predicted_label == true_label:\n",
        "                correct += 1\n",
        "            else:\n",
        "                error_info = {\n",
        "                    \"index\": i,\n",
        "                    \"original_index\": test_metadata[i][\"index\"],\n",
        "                    \"message\": query_text,\n",
        "                    \"true_label\": true_label,\n",
        "                    \"predicted_label\": predicted_label,\n",
        "                    \"vote_scores\": result[\"vote_scores\"],\n",
        "                    \"neighbors\": result[\"neighbors\"]\n",
        "                }\n",
        "                errors.append(error_info)\n",
        "\n",
        "        accuracy = correct / total\n",
        "        results[k] = accuracy\n",
        "        all_errors[k] = errors\n",
        "\n",
        "        print(f\"Accuracy with k={k}: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "        print(f\"Errors: {len(errors)}/{total}\")\n",
        "\n",
        "    return results, all_errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MMa_QTKM4Ghd"
      },
      "outputs": [],
      "source": [
        "def enhanced_spam_classifier_pipeline(user_input, index, train_metadata, class_weights, best_alpha, k=5, explain=False):\n",
        "    \"\"\"Enhanced spam classification with custom weighting and subcategorization\"\"\"\n",
        "\n",
        "    print(f'\\n***Classifying: \"{user_input}\"')\n",
        "    print(f\"***Using alpha={best_alpha:.1f}, k={k}\")\n",
        "\n",
        "    # Get prediction with weighted KNN\n",
        "    result = classify_with_weighted_knn(\n",
        "        user_input, model, tokenizer, device, index, train_metadata,\n",
        "        class_weights, k=k, alpha=best_alpha, explain=explain\n",
        "    )\n",
        "\n",
        "    prediction = result[\"prediction\"]\n",
        "    vote_scores = result[\"vote_scores\"]\n",
        "    neighbors = result[\"neighbors\"]\n",
        "\n",
        "    print(f\"***Prediction: {prediction.upper()}\")\n",
        "    print(f\"***Vote Scores: Ham={vote_scores['ham']:.3f}, Spam={vote_scores['spam']:.3f}\")\n",
        "    print(f\"***Saliency Weight: {result['saliency_weight']:.3f}\")\n",
        "\n",
        "    # If spam, classify subcategory\n",
        "    subcategory = None\n",
        "    if prediction == \"spam\":\n",
        "        subcategories = classify_spam_subcategory([user_input], model, tokenizer, device)\n",
        "        subcategory = subcategories[0] if subcategories else \"spam_khac\"\n",
        "        print(f\"***Spam Subcategory: {subcategory}\")\n",
        "\n",
        "    print(\"\\n***Top neighbors:\")\n",
        "    for i, neighbor in enumerate(neighbors, 1):\n",
        "        print(f\"{i}. Label: {neighbor['label']} | Similarity: {neighbor['score']:.4f} | Weight: {neighbor['weight']:.4f}\")\n",
        "        print(f\"   Message: {neighbor['message']}\")\n",
        "        print()\n",
        "\n",
        "    final_result = {\n",
        "        \"prediction\": prediction,\n",
        "        \"subcategory\": subcategory,\n",
        "        \"vote_scores\": vote_scores,\n",
        "        \"neighbors\": neighbors,\n",
        "        \"saliency_weight\": result[\"saliency_weight\"],\n",
        "        \"alpha\": best_alpha\n",
        "    }\n",
        "\n",
        "    if explain and result.get(\"tokens\"):\n",
        "        final_result[\"tokens\"] = result[\"tokens\"]\n",
        "        final_result[\"saliency_scores\"] = result[\"saliency_scores\"]\n",
        "\n",
        "    return final_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIlko1dEQ42g"
      },
      "source": [
        "##Run Pipeline (Bản mới)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ClryMRA-Q8CJ"
      },
      "outputs": [],
      "source": [
        "def run_enhanced_pipeline(messages, labels, test_size=0.2, use_augmentation=True):\n",
        "    \"\"\"Run the complete enhanced spam classification pipeline\"\"\"\n",
        "\n",
        "    print(\"=== Enhanced Spam Classification Pipeline ===\")\n",
        "\n",
        "    # 1. THÊM DATA AUGMENTATION\n",
        "    if use_augmentation:\n",
        "        print(\"\\n=== Data Augmentation ===\")\n",
        "\n",
        "        try:\n",
        "            # 1.1. Hỏi người dùng chọn cách augmentation\n",
        "            print(\"Chọn cách data augmentation:\")\n",
        "            print(\"1. Sinh 70 câu tinh vi bằng LLM (dùng API Together.ai)\")\n",
        "            print(\"2. Dùng cụm câu có sẵn trong code (không cần mạng/API)\")\n",
        "            aug_mode = input(\"👉 Nhập 1 hoặc 2: \").strip()\n",
        "\n",
        "            use_llm = aug_mode == \"1\"\n",
        "            gen = HardExampleGenerator(\n",
        "                dataset_path=\"/content/2cls_spam_text_cls.csv\",\n",
        "                alpha_spam=1.0,\n",
        "                alpha_ham=0.3,\n",
        "                use_llm_phrases=use_llm\n",
        "            )\n",
        "\n",
        "            if use_llm:\n",
        "                api_key = input(\"🔑 Nhập Together.ai API key (nhấn Enter để bỏ qua): \").strip()\n",
        "                if api_key:\n",
        "                    llm_spam = gen.generate_like_spam_ham(label='spam', n_per_group=10, api_key=api_key)\n",
        "                    llm_ham = gen.generate_like_spam_ham(label='ham', n_per_group=10, api_key=api_key)\n",
        "                    gen.load_llm_phrases(spam_list=llm_spam, ham_list=llm_ham)\n",
        "                else:\n",
        "                    print(\"⚠️ Không có API key. Sử dụng cụm có sẵn.\")\n",
        "                    gen.spam_groups = gen._init_spam_phrases()\n",
        "                    gen.ham_groups = gen._init_ham_phrases()\n",
        "            else:\n",
        "                print(\"ℹ️ Sử dụng cụm đã được hardcode trong class.\")\n",
        "\n",
        "            # 1.2. Sinh dữ liệu\n",
        "            gen.generate_hard_spam(\"/content/hard_spam_generated_auto.csv\")\n",
        "            gen.generate_hard_ham(\"/content/hard_ham_generated_auto.csv\")\n",
        "            augmented_messages, augmented_labels = gen.generate_synonym_replacement(messages, labels, aug_ratio=0.2)\n",
        "\n",
        "            # 1.3. Gộp tất cả lại thành 1 DataFrame mới\n",
        "            df_base = gen.df\n",
        "            df_hard_spam = pd.read_csv(\"/content/hard_spam_generated_auto.csv\")\n",
        "            df_hard_ham = pd.read_csv(\"/content/hard_ham_generated_auto.csv\")\n",
        "            df_synonym = pd.DataFrame({\"Category\": augmented_labels, \"Message\": augmented_messages})\n",
        "            df = pd.concat([df_base, df_hard_spam, df_hard_ham, df_synonym], ignore_index=True)\n",
        "\n",
        "            print(f\"📈 Tổng dữ liệu sau augmentation: {len(df)} samples.\")\n",
        "\n",
        "            # 1.4. Cập nhật messages & labels\n",
        "            messages = df[\"Message\"].tolist()\n",
        "            labels = df[\"Category\"].tolist()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Augmentation failed: {e}\")\n",
        "            print(\"ℹ️ Tiếp tục với dữ liệu gốc...\")\n",
        "            df = pd.read_csv(\"/content/2cls_spam_text_cls.csv\")\n",
        "            messages = df[\"Message\"].tolist()\n",
        "            labels = df[\"Category\"].tolist()\n",
        "    else:\n",
        "        print(\"ℹ️ Data augmentation disabled\")\n",
        "        df = pd.read_csv(\"/content/2cls_spam_text_cls.csv\")\n",
        "        messages = df[\"Message\"].tolist()\n",
        "        labels = df[\"Category\"].tolist()\n",
        "\n",
        "    # 1.5. Sau augmentation (hoặc không), encode label\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(labels)\n",
        "\n",
        "    # 2. Generate embeddings\n",
        "    print(\"Generating embeddings...\")\n",
        "    X_embeddings = get_embeddings(messages, model, tokenizer, device)\n",
        "\n",
        "    # 3. Create metadata\n",
        "    metadata = [{\"index\": i, \"message\": message, \"label\": label, \"label_encoded\": y[i]}\n",
        "                for i, (message, label) in enumerate(zip(messages, labels))]\n",
        "\n",
        "    # 4. Train-test split\n",
        "    X_train_emb, X_test_emb, train_metadata, test_metadata = train_test_split(\n",
        "        X_embeddings, metadata, test_size=test_size, random_state=42,\n",
        "        stratify=[m[\"label\"] for m in metadata]\n",
        "    )\n",
        "\n",
        "    # 5. Create FAISS index\n",
        "    print(\"Creating FAISS index...\")\n",
        "    dimension = X_train_emb.shape[1]\n",
        "    index = faiss.IndexFlatIP(dimension)\n",
        "    index.add(X_train_emb.astype(\"float32\"))\n",
        "\n",
        "    # 6. Calculate class weights\n",
        "    train_labels = [m[\"label\"] for m in train_metadata]\n",
        "    class_weights = calculate_class_weights(train_labels)\n",
        "\n",
        "    # 7. Optimize alpha parameter\n",
        "    test_labels = [m[\"label\"] for m in test_metadata]\n",
        "    best_alpha, alpha_results = optimize_alpha_parameter(\n",
        "        X_test_emb, test_labels, test_metadata, index, train_metadata, class_weights\n",
        "    )\n",
        "\n",
        "    # 8. Final evaluation\n",
        "    print(\"\\n=== Final Evaluation ===\")\n",
        "    accuracy_results, error_results = evaluate_weighted_knn_accuracy(\n",
        "        X_test_emb, test_labels, test_metadata, index, train_metadata,\n",
        "        class_weights, best_alpha, k_values=[1, 3, 5]\n",
        "    )\n",
        "\n",
        "    # 9. Analyze spam subcategories\n",
        "    spam_texts = [m[\"message\"] for m in test_metadata if m[\"label\"] == \"spam\"]\n",
        "    if spam_texts:\n",
        "        print(f\"\\n=== Spam Subcategory Analysis ===\")\n",
        "        spam_subcategories = classify_spam_subcategory(spam_texts, model, tokenizer, device)\n",
        "        subcat_counts = Counter(spam_subcategories)\n",
        "\n",
        "        print(\"Spam subcategory distribution:\")\n",
        "        for subcat, count in subcat_counts.items():\n",
        "            print(f\"  {subcat}: {count} ({count/len(spam_texts)*100:.1f}%)\")\n",
        "\n",
        "    # 10. Save results\n",
        "    results = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"model\": model_name,\n",
        "        \"test_size\": len(X_test_emb),\n",
        "        \"best_alpha\": best_alpha,\n",
        "        \"alpha_results\": alpha_results,\n",
        "        \"accuracy_results\": accuracy_results,\n",
        "        \"class_weights\": class_weights,\n",
        "        \"spam_subcategories\": dict(subcat_counts) if spam_texts else {}\n",
        "    }\n",
        "\n",
        "    with open(\"enhanced_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"\\n*** Results saved to enhanced_results.json ***\")\n",
        "\n",
        "    return {\n",
        "    \"index\": index,\n",
        "    \"train_metadata\": train_metadata,\n",
        "    \"test_metadata\": test_metadata,\n",
        "    \"class_weights\": class_weights,\n",
        "    \"best_alpha\": best_alpha,\n",
        "    \"results\": results,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "706A09z99EJs"
      },
      "source": [
        "## Apply test case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZOFJuoMDhBoM"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def render_heatmap(tokens, saliencies):\n",
        "  html = \"\"\n",
        "  for token, score in zip(tokens, saliencies):\n",
        "    html += f\"<span style='background: rgba(255,0,0,{score:.2f})'>{token}</span> \"\n",
        "  return HTML(f\"<div style='font-size:16px; line-height:1.5'>{html}</div>\")\n",
        "\n",
        "def test_enhanced_classifier(pipeline_results):\n",
        "    index = pipeline_results[\"index\"]\n",
        "    train_metadata = pipeline_results[\"train_metadata\"]\n",
        "    class_weights = pipeline_results[\"class_weights\"]\n",
        "    best_alpha = pipeline_results[\"best_alpha\"]\n",
        "\n",
        "    test_cases_combined = [\n",
        "        {\"message\": \"Congratulations! You've won $1000! Click here to claim your prize now!\", \"expected\": \"spam\"},\n",
        "        {\"message\": \"URGENT: Your account will be suspended. Verify immediately to avoid closure.\", \"expected\": \"spam\"},\n",
        "        {\"message\": \"Thanks for your help with the project. The presentation went very well.\", \"expected\": \"ham\"},\n",
        "        {\"message\": \"Chào bạn, bạn có khỏe không? Ngày mai mình gặp nhau uống cà phê nhé?\", \"expected\": \"ham\"},\n",
        "        {\"message\": \"Cuộc họp đã được dời lại lúc 3 giờ chiều. Bạn vui lòng cập nhật lịch.\", \"expected\": \"ham\"},\n",
        "        {\"message\": \"Cảm ơn bạn đã giúp đỡ dự án. Buổi thuyết trình đã diễn ra rất tốt.\", \"expected\": \"ham\"},\n",
        "    ]\n",
        "\n",
        "    api_key = input(\"Nhập Together.ai API key (nhấn Enter để bỏ qua): \").strip()\n",
        "\n",
        "    # Khởi tạo generator\n",
        "    use_llm = bool(api_key)\n",
        "    gen = HardExampleGenerator(\"/content/2cls_spam_text_cls.csv\", use_llm_phrases=use_llm)\n",
        "\n",
        "\n",
        "    if api_key:\n",
        "        print(\"\\n\\n=== Generating LLM-based Test Cases ===\")\n",
        "        try:\n",
        "            spam_like_questions = gen.generate_user_like_spam_ham(\n",
        "                label=\"spam\", n=5, api_key=api_key, model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "            )\n",
        "            ham_legit_questions = gen.generate_user_like_spam_ham(\n",
        "                label=\"ham\", n=5, api_key=api_key, model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "            )\n",
        "            for msg in spam_like_questions:\n",
        "                test_cases_combined.append({\"message\": msg, \"expected\": \"spam\"})\n",
        "            for msg in ham_legit_questions:\n",
        "                test_cases_combined.append({\"message\": msg, \"expected\": \"ham\"})\n",
        "            print(\" LLM-generated examples created.\")\n",
        "        except Exception as e:\n",
        "            print(f\" Lỗi sinh ví dụ LLM: {e}\")\n",
        "    else:\n",
        "        print(\"ℹ Không có API key. Sử dụng test case thủ công.\")\n",
        "\n",
        "    print(\"\\n\\n=== BẮT ĐẦU TEST ===\")\n",
        "    for i, test_case in enumerate(test_cases_combined, 1):\n",
        "        message = test_case[\"message\"]\n",
        "        expected_label = test_case[\"expected\"]\n",
        "\n",
        "        print(f\"\\n--- Example {i}: {message[:50]}... ---\")\n",
        "\n",
        "        result = enhanced_spam_classifier_pipeline(\n",
        "            message, index, train_metadata, class_weights, best_alpha, k=5, explain=True\n",
        "        )\n",
        "\n",
        "        predicted_label = result[\"prediction\"]\n",
        "        print(f\" Prediction: {predicted_label} (Expected: {expected_label})\")\n",
        "\n",
        "        if \"tokens\" in result and \"saliency_scores\" in result:\n",
        "            print(\" Saliency Heatmap:\")\n",
        "            display(render_heatmap(result[\"tokens\"], result[\"saliency_scores\"]))\n",
        "        else:\n",
        "            print(\" Không thể hiển thị heatmap.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CKRvIGCI9ngn"
      },
      "outputs": [],
      "source": [
        "def integrate_with_existing_data(messages, labels):\n",
        "    \"\"\"\n",
        "    Integrate with your existing messages and labels data\n",
        "\n",
        "    Args:\n",
        "        messages: List of email texts\n",
        "        labels: List of 'ham'/'spam' labels\n",
        "    \"\"\"\n",
        "    print(\"=== Starting Enhanced Pipeline ===\")\n",
        "\n",
        "    # Run the enhanced pipeline\n",
        "    pipeline_results = run_enhanced_pipeline(messages, labels)\n",
        "\n",
        "    # Test with examples\n",
        "    test_enhanced_classifier(pipeline_results)\n",
        "\n",
        "    return pipeline_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfzCB99294S6",
        "outputId": "94522bfc-9b49-4fe6-cda8-bd5ad0cf9b42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TESTING WITH GOOGLE DRIVE DATASET\n",
            "============================================================\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1N7rk-kfnDFIGMeX0ROVTjKh71gcgx-7R\n",
            "To: /content/2cls_spam_text_cls.csv\n",
            "100% 486k/486k [00:00<00:00, 80.8MB/s]\n",
            "First 5 records:\n",
            "  Category                                            Message\n",
            "0      ham  Go until jurong point, crazy.. Available only ...\n",
            "1      ham                      Ok lar... Joking wif u oni...\n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      ham  U dun say so early hor... U c already then say...\n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
            "Preprocessing dataframe...\n",
            "Columns available: ['Category', 'Message']\n",
            "Using text column: Message\n",
            "Using label column: Category\n",
            "Label distribution:\n",
            "  ham: 4825 samples\n",
            "  spam: 747 samples\n",
            "Processed 5572 messages\n",
            "=== Enhanced Spam Classification Pipeline ===\n",
            "\n",
            "=== Data Augmentation ===\n",
            "Chọn cách data augmentation:\n",
            "1. Sinh 70 câu tinh vi bằng LLM (dùng API Together.ai)\n",
            "2. Dùng cụm câu có sẵn trong code (không cần mạng/API)\n",
            "👉 Nhập 1 hoặc 2: 1\n",
            "🔑 Nhập Together.ai API key (nhấn Enter để bỏ qua): a4910347ea0b1f86be877cd19899dd0bd3f855487a0b80eb611a64c0abf7a782\n",
            "📡 Generating SPAM – Group: financial ...\n",
            "📡 Generating SPAM – Group: promotion ...\n",
            "📡 Generating SPAM – Group: lottery ...\n",
            "📡 Generating SPAM – Group: scam_alert ...\n",
            "📡 Generating SPAM – Group: call_to_action ...\n",
            "📡 Generating SPAM – Group: social_engineering ...\n",
            "📡 Generating SPAM – Group: obfuscated ...\n",
            "📡 Generating HAM – Group: financial ...\n",
            "📡 Generating HAM – Group: promotion ...\n",
            "📡 Generating HAM – Group: lottery ...\n",
            "📡 Generating HAM – Group: scam_alert ...\n",
            "📡 Generating HAM – Group: call_to_action ...\n",
            "📡 Generating HAM – Group: social_engineering ...\n",
            "📡 Generating HAM – Group: obfuscated ...\n",
            "✅ Đã load 140 câu LLM và chia thành 7 nhóm spam/ham.\n",
            "✅ Sinh 4078 hard spam -> /content/hard_spam_generated_auto.csv\n",
            "✅ Sinh 1223 hard ham -> /content/hard_ham_generated_auto.csv\n",
            "✅ Synonym Replacement: sinh tối đa 1114 câu.\n",
            "✅ Đã sinh 1023 câu augmented thực tế.\n",
            "📈 Tổng dữ liệu sau augmentation: 11896 samples.\n",
            "Generating embeddings...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings: 100%|██████████| 372/372 [00:57<00:00,  6.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating FAISS index...\n",
            "Class distribution:\n",
            "  spam: 3975 samples (weight: 1.197)\n",
            "  ham: 5541 samples (weight: 0.859)\n",
            "Optimizing alpha parameter...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing alpha values:   9%|▉         | 1/11 [00:29<04:52, 29.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alpha: 0.0, Accuracy: 0.9626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTesting alpha values:  18%|█▊        | 2/11 [00:58<04:23, 29.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alpha: 0.1, Accuracy: 0.9626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTesting alpha values:  27%|██▋       | 3/11 [01:27<03:51, 28.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alpha: 0.2, Accuracy: 0.9626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTesting alpha values:  36%|███▋      | 4/11 [02:05<03:49, 32.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alpha: 0.3, Accuracy: 0.9626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTesting alpha values:  45%|████▌     | 5/11 [02:50<03:42, 37.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alpha: 0.4, Accuracy: 0.9626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTesting alpha values:  55%|█████▍    | 6/11 [03:26<03:03, 36.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alpha: 0.5, Accuracy: 0.9626\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    TEST_KAGGLE = False\n",
        "    TEST_GDRIVE = True\n",
        "\n",
        "    results_summary = {}\n",
        "\n",
        "    # Test 1: Kaggle Dataset\n",
        "    if TEST_KAGGLE:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"TESTING WITH KAGGLE DATASET\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "\n",
        "        messages, labels = load_dataset(source='kaggle')\n",
        "\n",
        "        # Run enhanced pipeline\n",
        "        pipeline_results = run_enhanced_pipeline(messages, labels, test_size=0.2, use_augmentation=True)\n",
        "\n",
        "        results_summary['kaggle'] = {\n",
        "            'samples': len(messages),\n",
        "            'best_alpha': pipeline_results['best_alpha'],\n",
        "            'accuracy': pipeline_results['results']['accuracy_results']\n",
        "        }\n",
        "\n",
        "        # Test with examples\n",
        "        test_enhanced_classifier(pipeline_results)\n",
        "\n",
        "\n",
        "\n",
        "    # Test 2: Google Drive Dataset\n",
        "    if TEST_GDRIVE:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"TESTING WITH GOOGLE DRIVE DATASET\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        messages, labels = load_dataset(source='gdrive', file_id='1N7rk-kfnDFIGMeX0ROVTjKh71gcgx-7R')\n",
        "\n",
        "        # Run enhanced pipeline\n",
        "        pipeline_results = run_enhanced_pipeline(messages, labels, test_size=0.2, use_augmentation=True)\n",
        "        results_summary['gdrive'] = {\n",
        "            'samples': len(messages),\n",
        "            'best_alpha': pipeline_results['best_alpha'],\n",
        "            'accuracy': pipeline_results['results']['accuracy_results']\n",
        "        }\n",
        "\n",
        "        # Test with examples\n",
        "        test_enhanced_classifier(pipeline_results)\n",
        "\n",
        "\n",
        "\n",
        "    # Final Summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FINAL RESULTS SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for dataset, results in results_summary.items():\n",
        "        print(f\"\\n{dataset.upper()} Dataset:\")\n",
        "        if 'error' in results:\n",
        "            print(f\"Error: {results['error']}\")\n",
        "        else:\n",
        "            print(f\"Samples: {results['samples']}\")\n",
        "            print(f\"Best Alpha: {results['best_alpha']:.1f}\")\n",
        "            print(f\"Accuracy Results:\")\n",
        "            for k, acc in results['accuracy'].items():\n",
        "                print(f\"      k={k}: {acc:.4f} ({acc*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEixkVcApnxb"
      },
      "source": [
        "## Kết quả dùng LLM hoàn toàn tự động"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOBdOhZXprth"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    TEST_KAGGLE = False\n",
        "    TEST_GDRIVE = True\n",
        "\n",
        "    results_summary = {}\n",
        "\n",
        "    # Test 1: Kaggle Dataset\n",
        "    if TEST_KAGGLE:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"TESTING WITH KAGGLE DATASET\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "\n",
        "        messages, labels = load_dataset(source='kaggle')\n",
        "\n",
        "        # Run enhanced pipeline\n",
        "        pipeline_results = run_enhanced_pipeline(messages, labels, test_size=0.2, use_augmentation=True)\n",
        "\n",
        "        results_summary['kaggle'] = {\n",
        "            'samples': len(messages),\n",
        "            'best_alpha': pipeline_results['best_alpha'],\n",
        "            'accuracy': pipeline_results['results']['accuracy_results']\n",
        "        }\n",
        "\n",
        "        # Test with examples\n",
        "        test_enhanced_classifier(pipeline_results)\n",
        "\n",
        "\n",
        "\n",
        "    # Test 2: Google Drive Dataset\n",
        "    if TEST_GDRIVE:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"TESTING WITH GOOGLE DRIVE DATASET\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        messages, labels = load_dataset(source='gdrive', file_id='1N7rk-kfnDFIGMeX0ROVTjKh71gcgx-7R')\n",
        "\n",
        "        # Run enhanced pipeline\n",
        "        pipeline_results = run_enhanced_pipeline(messages, labels, test_size=0.2, use_augmentation=True)\n",
        "        results_summary['gdrive'] = {\n",
        "            'samples': len(messages),\n",
        "            'best_alpha': pipeline_results['best_alpha'],\n",
        "            'accuracy': pipeline_results['results']['accuracy_results']\n",
        "        }\n",
        "\n",
        "        # Test with examples\n",
        "        test_enhanced_classifier(pipeline_results)\n",
        "\n",
        "\n",
        "\n",
        "    # Final Summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FINAL RESULTS SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for dataset, results in results_summary.items():\n",
        "        print(f\"\\n{dataset.upper()} Dataset:\")\n",
        "        if 'error' in results:\n",
        "            print(f\"Error: {results['error']}\")\n",
        "        else:\n",
        "            print(f\"Samples: {results['samples']}\")\n",
        "            print(f\"Best Alpha: {results['best_alpha']:.1f}\")\n",
        "            print(f\"Accuracy Results:\")\n",
        "            for k, acc in results['accuracy'].items():\n",
        "                print(f\"      k={k}: {acc:.4f} ({acc*100:.2f}%)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "sj4Zf0odD0Xy",
        "FohSS_hIXWqj",
        "toPKkX5oZc3B",
        "eadqgADs78LK",
        "ydI6ukpn8Jcm",
        "0vi-QPsl8P-G",
        "i-gUpbCg8X7Q",
        "mpLrUAVE8kNx",
        "SmQBC6I78pLX",
        "GEF558W68vcf",
        "H3gcZZke8_qd"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0167b157231b4dceb946ed2729b9cf8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "019bf3423ae24597a42e55e6f59e7138": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7610cbb6922b49e7bfb8409a22132d8f",
              "IPY_MODEL_ef4792efbe1a4aacbd27eecb4e194d83",
              "IPY_MODEL_c87e66e252e64007b67d1f316093647a"
            ],
            "layout": "IPY_MODEL_70f1fa4841304eaa9317eca3ceafbf08"
          }
        },
        "022f3650c8654b4997f081f932075f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0879f38663314487bf9dbec24fb1cf38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8605b8cf73b64ab8927b67c27ff76ab1",
            "placeholder": "​",
            "style": "IPY_MODEL_08ef224a00974f61841917923e214a0f",
            "value": "config.json: 100%"
          }
        },
        "08ef224a00974f61841917923e214a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c8d4b1662204eef87643c307eaa9ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a636cde9125456c8018d8852272fcfc",
            "max": 418,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1014794fd0194aacbe7656a336536237",
            "value": 418
          }
        },
        "1014794fd0194aacbe7656a336536237": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14aa3171cb1847adab5be8b2ff36c69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60f6d1a3686141fabacd6939c5efad1d",
            "placeholder": "​",
            "style": "IPY_MODEL_55d578a48e3a47218f53008d46fa6e84",
            "value": " 694/694 [00:00&lt;00:00, 30.7kB/s]"
          }
        },
        "1c086427b425430e8e2de80d291037bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_755d7a5f8a63489788e7ee762ca0371d",
            "max": 694,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_022f3650c8654b4997f081f932075f38",
            "value": 694
          }
        },
        "1d8e05fc52dd433398deb92d412253e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29588c59102d406f8bace65fc8185279": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c5e523eca5e412eade789ebadbd0c88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3302260d5d0845f6adf34cc271961404": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8293d136ae84fb58f74603ea7769bd4",
            "placeholder": "​",
            "style": "IPY_MODEL_9ccf886b765e4bfabdc77af7dc9f9b23",
            "value": "tokenizer.json: 100%"
          }
        },
        "35875c4539c641579752e56ee9fc5a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbc1f06dbf214c31af5bb104cb79c820",
              "IPY_MODEL_6e7889ce4c37453d8fa2a8758a3888ec",
              "IPY_MODEL_e56d6e694628400dbfe79f7bfbecac43"
            ],
            "layout": "IPY_MODEL_1d8e05fc52dd433398deb92d412253e4"
          }
        },
        "36acabaf71e447d3a0fba27d9bbfe3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3302260d5d0845f6adf34cc271961404",
              "IPY_MODEL_98c5fcba5b754a8fa7811dda80cf9bac",
              "IPY_MODEL_782061da906e41578cd4cf726ec35dd6"
            ],
            "layout": "IPY_MODEL_e9b2d7efce564afc8479194a277841cd"
          }
        },
        "3729e4aaa49b4f21b8f64f5a76845a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "376d883743364ba6876bf72f1a7c455b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "383f74f83f1e4016a3a63e2b6b996e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "450e743b06524243ae6373a8c3a1f9ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d578a48e3a47218f53008d46fa6e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dfe0811eded42939ff30f2f9289e9f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "604cb193401249a2b5b75399fb652e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb06157d50874e949248b2dd57078e79",
            "placeholder": "​",
            "style": "IPY_MODEL_6aa51a096ff34198b7cb136863d31373",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "60f6d1a3686141fabacd6939c5efad1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a636cde9125456c8018d8852272fcfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa51a096ff34198b7cb136863d31373": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e7889ce4c37453d8fa2a8758a3888ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_376d883743364ba6876bf72f1a7c455b",
            "max": 1112201288,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7502c94c5b1947efa3ae526bac9e2019",
            "value": 1112201288
          }
        },
        "70dad4b0096e4c6dbe9a04871ebdce4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_865074dd95e84e1c97e38b5078bddbfe",
            "placeholder": "​",
            "style": "IPY_MODEL_0167b157231b4dceb946ed2729b9cf8c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "70f1fa4841304eaa9317eca3ceafbf08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7502c94c5b1947efa3ae526bac9e2019": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "755d7a5f8a63489788e7ee762ca0371d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7610cbb6922b49e7bfb8409a22132d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dfe0811eded42939ff30f2f9289e9f0",
            "placeholder": "​",
            "style": "IPY_MODEL_3729e4aaa49b4f21b8f64f5a76845a5f",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "77fdaa5853dc444b91bf43b59edd825c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70dad4b0096e4c6dbe9a04871ebdce4b",
              "IPY_MODEL_0c8d4b1662204eef87643c307eaa9ed2",
              "IPY_MODEL_8b436dcd9dc44f9e9021f6c3c35cafd7"
            ],
            "layout": "IPY_MODEL_d64a5b0e016540a48b0cbba21dbfa656"
          }
        },
        "782061da906e41578cd4cf726ec35dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e355973f30452e921038a93929cf03",
            "placeholder": "​",
            "style": "IPY_MODEL_fff71ab1439142dba67b1a70e9441182",
            "value": " 17.1M/17.1M [00:00&lt;00:00, 50.4MB/s]"
          }
        },
        "7a0c4dbb7950486aad0802ae62160eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8605b8cf73b64ab8927b67c27ff76ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "865074dd95e84e1c97e38b5078bddbfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88e2b54b3afe4833b24ebbfd40c30b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0879f38663314487bf9dbec24fb1cf38",
              "IPY_MODEL_1c086427b425430e8e2de80d291037bc",
              "IPY_MODEL_14aa3171cb1847adab5be8b2ff36c69d"
            ],
            "layout": "IPY_MODEL_df3a97903d0048dd918611e0a246edb5"
          }
        },
        "8aa92263ef3247f8a340a066859d52c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b436dcd9dc44f9e9021f6c3c35cafd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cfcbf51d9b44b9a9cec3aeb075b8490",
            "placeholder": "​",
            "style": "IPY_MODEL_95b82a2d5ef1437d939bd5c060c45455",
            "value": " 418/418 [00:00&lt;00:00, 6.40kB/s]"
          }
        },
        "95b82a2d5ef1437d939bd5c060c45455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98c5fcba5b754a8fa7811dda80cf9bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d57d4f52940f480e95724ca6190863e1",
            "max": 17082660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0959f37ffcf44e1b6ceb1422909fdc5",
            "value": 17082660
          }
        },
        "9ccf886b765e4bfabdc77af7dc9f9b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cfcbf51d9b44b9a9cec3aeb075b8490": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d06e8c002e84f45982d8ffc0abf184b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7e355973f30452e921038a93929cf03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a879b09cb58b40f9a4dd34fb571ef982": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad5ddd62d4a243b59c1e306936b5e502": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc5aa094a104c3385ceadabf7146f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8293d136ae84fb58f74603ea7769bd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87e66e252e64007b67d1f316093647a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29588c59102d406f8bace65fc8185279",
            "placeholder": "​",
            "style": "IPY_MODEL_afc5aa094a104c3385ceadabf7146f0a",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 19.0MB/s]"
          }
        },
        "cbc1f06dbf214c31af5bb104cb79c820": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad5ddd62d4a243b59c1e306936b5e502",
            "placeholder": "​",
            "style": "IPY_MODEL_9d06e8c002e84f45982d8ffc0abf184b",
            "value": "model.safetensors: 100%"
          }
        },
        "cd7a46d1cdd848e2a1edee1fb10f2c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_450e743b06524243ae6373a8c3a1f9ad",
            "max": 280,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8aa92263ef3247f8a340a066859d52c0",
            "value": 280
          }
        },
        "cedadc9bd4bf4db5a32b65f2b9c9f064": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_604cb193401249a2b5b75399fb652e00",
              "IPY_MODEL_cd7a46d1cdd848e2a1edee1fb10f2c74",
              "IPY_MODEL_f5e7816826084cfe86e73c63ebf24060"
            ],
            "layout": "IPY_MODEL_a879b09cb58b40f9a4dd34fb571ef982"
          }
        },
        "d0959f37ffcf44e1b6ceb1422909fdc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d57d4f52940f480e95724ca6190863e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d64a5b0e016540a48b0cbba21dbfa656": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8e03c868d214f37854a641c2e9e8d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df3a97903d0048dd918611e0a246edb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1d51c03e323415594403af0ad54e11a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e56d6e694628400dbfe79f7bfbecac43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2ef3a9a3baa4125aafdac9a1492962d",
            "placeholder": "​",
            "style": "IPY_MODEL_7a0c4dbb7950486aad0802ae62160eae",
            "value": " 1.11G/1.11G [00:10&lt;00:00, 202MB/s]"
          }
        },
        "e9b2d7efce564afc8479194a277841cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef4792efbe1a4aacbd27eecb4e194d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1d51c03e323415594403af0ad54e11a",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8e03c868d214f37854a641c2e9e8d9d",
            "value": 5069051
          }
        },
        "f2ef3a9a3baa4125aafdac9a1492962d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5e7816826084cfe86e73c63ebf24060": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c5e523eca5e412eade789ebadbd0c88",
            "placeholder": "​",
            "style": "IPY_MODEL_383f74f83f1e4016a3a63e2b6b996e2c",
            "value": " 280/280 [00:00&lt;00:00, 9.65kB/s]"
          }
        },
        "fb06157d50874e949248b2dd57078e79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fff71ab1439142dba67b1a70e9441182": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
