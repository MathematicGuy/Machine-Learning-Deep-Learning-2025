{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ls3L9w-mG9Zq"
   },
   "source": [
    "## **0. Download dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16367,
     "status": "ok",
     "timestamp": 1765274911926,
     "user": {
      "displayName": "Quang Hien",
      "userId": "09884577578529200534"
     },
     "user_tz": -420
    },
    "id": "XR2hDC-kBMyd",
    "outputId": "bcf611d3-81f3-442a-e5c2-e648ce6941cf"
   },
   "outputs": [],
   "source": [
    "# # https://drive.google.com/file/d/1oHsZmpwvgZw8dT2WRdLFOeOlbzAiilBD/view\n",
    "# !gdown 1oHsZmpwvgZw8dT2WRdLFOeOlbzAiilBD\n",
    "# !unzip -q data/img_cls_weather_dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQeJEySoG_Qx"
   },
   "source": [
    "## **1. Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "a_s_9iDJHNMJ"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIONh0Nnx9HA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 59\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vf2wyW6hH6LM"
   },
   "source": [
    "## **2. Read dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aky_tAMuNT12"
   },
   "outputs": [],
   "source": [
    "root_dir = 'data/img_cls_weather_dataset'\n",
    "classes = {\n",
    "    label_idx: class_name \\\n",
    "        for label_idx, class_name in enumerate(\n",
    "            sorted(os.listdir(root_dir))\n",
    "        )\n",
    "}\n",
    "\n",
    "img_paths = []\n",
    "labels = []\n",
    "for label_idx, class_name in classes.items():\n",
    "    class_dir = os.path.join(root_dir, class_name)\n",
    "    for img_filename in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_filename)\n",
    "        img_paths.append(img_path)\n",
    "        labels.append(label_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W71YwGLtTb1C"
   },
   "source": [
    "## **3. Train, val, test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JDhW8oB3Sl3X"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m test_size = \u001b[32m0.125\u001b[39m\n\u001b[32m      3\u001b[39m is_shuffle = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m X_train, X_val, y_train, y_val = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_shuffle\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[32m     13\u001b[39m     X_train, y_train,\n\u001b[32m     14\u001b[39m     test_size=test_size,\n\u001b[32m     15\u001b[39m     random_state=seed,\n\u001b[32m     16\u001b[39m     shuffle=is_shuffle\n\u001b[32m     17\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Utilities\\miniconda\\envs\\dl\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Utilities\\miniconda\\envs\\dl\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2919\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2916\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Utilities\\miniconda\\envs\\dl\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2499\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2496\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2500\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2503\u001b[39m     )\n\u001b[32m   2505\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "val_size = 0.2\n",
    "test_size = 0.125\n",
    "is_shuffle = True\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    img_paths, labels,\n",
    "    test_size=val_size,\n",
    "    random_state=seed,\n",
    "    shuffle=is_shuffle\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=test_size,\n",
    "    random_state=seed,\n",
    "    shuffle=is_shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXx3le_nTe7K"
   },
   "source": [
    "## **4. Create pytorch dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKoGy1rhH7ol"
   },
   "outputs": [],
   "source": [
    "class WeatherDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X, y,\n",
    "        transform=None\n",
    "    ):\n",
    "        self.transform = transform\n",
    "        self.img_paths = X\n",
    "        self.labels = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N87jYgtTVEaW"
   },
   "source": [
    "## **5. Create data preprocessing function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urcklIg-VKT_"
   },
   "outputs": [],
   "source": [
    "def transform(img, img_size=(224, 224)):\n",
    "    img = img.resize(img_size)\n",
    "    img = np.array(img)[..., :3]\n",
    "    img = torch.tensor(img).permute(2, 0, 1).float()\n",
    "    normalized_img = img / 255.0\n",
    "\n",
    "    return normalized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJWxpyFVVIQC"
   },
   "source": [
    "## **6. Create dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2INWkQ2UxCE"
   },
   "outputs": [],
   "source": [
    "train_dataset = WeatherDataset(\n",
    "    X_train, y_train,\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset = WeatherDataset(\n",
    "    X_val, y_val,\n",
    "    transform=transform\n",
    ")\n",
    "test_dataset = WeatherDataset(\n",
    "    X_test, y_test,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MooDikjcWquF"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 256\n",
    "test_batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqgmcSFifl01"
   },
   "source": [
    "## **7. Create model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvNKVPY6mStX"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size=3, stride=stride, padding=1\n",
    "        )\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, out_channels,\n",
    "            kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        #? Change dimensions only. It doesn't look at neighbors;\n",
    "        #? it just looks at one pixel at a time.\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels, out_channels,\n",
    "                    kernel_size=1, stride=stride\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2\n",
    "        x += self.downsample(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMwlDUAOfoWi"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, residual_block, n_blocks_lst, n_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = self.create_layer(residual_block, 64, 64, n_blocks_lst[0], 1)\n",
    "        self.conv3 = self.create_layer(residual_block, 64, 128, n_blocks_lst[1], 2)\n",
    "        self.conv4 = self.create_layer(residual_block, 128, 256, n_blocks_lst[2], 2)\n",
    "        self.conv5 = self.create_layer(residual_block, 256, 512, n_blocks_lst[3], 2)\n",
    "        #? Adaptive: The number of output features is equal to the number of input planes.\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(512, n_classes)\n",
    "\n",
    "    def create_layer(self, residual_block, in_channels, out_channels, n_blocks, stride):\n",
    "        blocks = []\n",
    "        first_block = residual_block(in_channels, out_channels, stride)\n",
    "        blocks.append(first_block)\n",
    "\n",
    "        for idx in range(1, n_blocks):\n",
    "            block = residual_block(out_channels, out_channels, stride=1)\n",
    "            blocks.append(block)\n",
    "\n",
    "        block_sequential = nn.Sequential(*blocks)\n",
    "\n",
    "        return block_sequential\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ltB3OKvvLjN"
   },
   "outputs": [],
   "source": [
    "n_classes = len(list(classes.keys()))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = ResNet(\n",
    "    residual_block=ResidualBlock,\n",
    "    n_blocks_lst=[2, 2, 2, 2],\n",
    "    n_classes=n_classes\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 993,
     "status": "ok",
     "timestamp": 1765274919056,
     "user": {
      "displayName": "Quang Hien",
      "userId": "09884577578529200534"
     },
     "user_tz": -420
    },
    "id": "zaHaED-Pv4Z8",
    "outputId": "c74f6150-3822-4e8b-c4e6-a762038f3993"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "dummy_tensor = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_tensor)\n",
    "\n",
    "print('Output shape:', output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwUyHR5Ry8Ma"
   },
   "source": [
    "## **8. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6yK8gbkEjY4"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    loss = sum(losses) / len(losses)\n",
    "    acc = correct / total\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHlJ41gzlD73"
   },
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs\n",
    "):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        batch_train_losses = []\n",
    "\n",
    "        # Progress bar cho train tá»«ng batch\n",
    "        model.train()\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\")\n",
    "\n",
    "        for inputs, labels in train_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_train_losses.append(loss.item())\n",
    "\n",
    "        train_loss = sum(batch_train_losses) / len(batch_train_losses)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"EPOCH {epoch+1}: Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f} | Val acc: {val_acc:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxIchZovy-nN"
   },
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "epochs = 12\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 567864,
     "status": "ok",
     "timestamp": 1765275492035,
     "user": {
      "displayName": "Quang Hien",
      "userId": "09884577578529200534"
     },
     "user_tz": -420
    },
    "id": "fcz64qrvni-6",
    "outputId": "3dcea8ec-9869-46bd-e02a-c5d098d42bb3"
   },
   "outputs": [],
   "source": [
    "train_losses, val_losses = fit(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1765275492311,
     "user": {
      "displayName": "Quang Hien",
      "userId": "09884577578529200534"
     },
     "user_tz": -420
    },
    "id": "A0KLZhQh74fG",
    "outputId": "32378610-d5dc-4659-fd96-8bcb8473c1ea"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax[0].plot(train_losses)\n",
    "ax[0].set_title('Training Loss')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[1].plot(val_losses, color='orange')\n",
    "ax[1].set_title('Val Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQtRoAhDy9NO"
   },
   "source": [
    "## **9. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13258,
     "status": "ok",
     "timestamp": 1765275767609,
     "user": {
      "displayName": "Quang Hien",
      "userId": "09884577578529200534"
     },
     "user_tz": -420
    },
    "id": "TRiWE-wFqdrp",
    "outputId": "c89b48ec-17d7-478f-949b-4b1208fe0ad5"
   },
   "outputs": [],
   "source": [
    "val_loss, val_acc = evaluate(\n",
    "    model,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    device\n",
    ")\n",
    "test_loss, test_acc = evaluate(\n",
    "    model,\n",
    "    test_loader,\n",
    "    criterion,\n",
    "    device\n",
    ")\n",
    "\n",
    "print('Evaluation on val/test dataset')\n",
    "print('Val accuracy: ', val_acc)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891
    },
    "executionInfo": {
     "elapsed": 1062,
     "status": "ok",
     "timestamp": 1765275768672,
     "user": {
      "displayName": "Quang Hien",
      "userId": "09884577578529200534"
     },
     "user_tz": -420
    },
    "id": "ygxY8AjLh1Ap",
    "outputId": "68224d78-ff2a-4aec-85e8-27f2306643cf"
   },
   "outputs": [],
   "source": [
    "def predict_sample(model, img_path, transform, device, classes):\n",
    "    \"\"\"Predict class for a single image and return prediction details.\"\"\"\n",
    "    model.eval()\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        pred_class = output.argmax(dim=1).item()\n",
    "        pred_prob = probs[0, pred_class].item()\n",
    "    return classes[pred_class], pred_prob, img, probs[0].cpu().numpy()\n",
    "\n",
    "# Test inference on random samples from test set\n",
    "num_samples = 6\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "sample_indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "for idx, sample_idx in enumerate(sample_indices):\n",
    "    img_path = X_test[sample_idx]\n",
    "    true_label = classes[y_test[sample_idx]]\n",
    "\n",
    "    pred_class, pred_prob, img, probs = predict_sample(model, img_path, transform, device, classes)\n",
    "\n",
    "    axes[idx].imshow(img)\n",
    "    color = 'green' if true_label == pred_class else 'red'\n",
    "    axes[idx].set_title(f'True: {true_label}\\nPred: {pred_class} ({pred_prob:.2%})', fontsize=10, color=color)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
