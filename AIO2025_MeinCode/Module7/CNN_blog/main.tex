\documentclass[11pt]{article}
% Font & ngôn ngữ tiếng Việt (pdfLaTeX)
\usepackage[utf8]{inputenc}
\usepackage[T5]{fontenc}

% Biblatex + biber
% \usepackage[backend=biber, style=numeric, sorting=ynt]{biblatex}
% \addbibresource{references.bib}
% \DeclareBibliographyAlias{video}{misc}
\usepackage{hyperref}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\lstdefinestyle{shell}{
	language=bash,
	basicstyle=\ttfamily\small,
	commentstyle=\color{green!60!black},
	keywordstyle=\color{blue},
	stringstyle=\color{red},
	emphstyle=\color{purple},
	backgroundcolor=\color{gray!10},
	showstringspaces=false,
	frame=single,
	breaklines=true,
	emph={[1]\$\ },  % This is the key part: highlight the prompt
	emph=[1]{git, conda, m	kdir, cd, pip} % Also emphasize key commands
}

% Toán học & font Times
\usepackage{amsmath, amssymb, amsfonts, bm}

% Bảng biểu & căn lề
\usepackage{longtable}
\usepackage{array}
\usepackage{booktabs}

% Đồ họa & màu sắc
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{float}
\usepackage{subcaption}

% Liên kết & tham chiếu
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=red,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
}
\usepackage{bookmark}

% Dấu tick và x
\usepackage{pifont}
\newcommand{\xmark}{\ding{55}}
\newcommand{\cmark}{\ding{51}}

% Tiêu đề tùy chỉnh
\usepackage{titling}
\setlength{\droptitle}{-10em}
\renewcommand{\maketitle}{%
    \begin{center}
        \fontsize{18}{20}\selectfont\textbf{Understand and Build CNN from the Grounth Up and Intuition}\\[1em]
        \fontsize{14}{16}\selectfont Nhóm AIO\_TimeSeries\\[0.5em]
        \fontsize{14}{16}\selectfont Ngày 18 tháng 11 năm 2025
    \end{center}
    \vspace{1.5em}
}

% Format section (không đánh số)
\usepackage{titlesec}
\titleformat{\section}{\normalfont\Large\bfseries}{}{0em}{}

% Code block
\usepackage{listings}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstset{
    backgroundcolor=\color{backcolour},
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    numbers=left,
    numberstyle=\tiny\color{gray},
    captionpos=b
}

% Hộp màu
\usepackage[many]{tcolorbox}
\definecolor{lightgreenbox}{rgb}{0.85,0.95,0.85}
\newtcolorbox{summarybox}{
    colback=lightgreenbox,
    colframe=green!50!black,
    boxsep=5pt, arc=4pt,
    boxrule=0.5pt,
    left=10pt, right=10pt,
    top=10pt, bottom=10pt,
}


% Layout trang
\setlength{\topmargin}{-0.7in}
\setlength{\textheight}{9.25in}
\setlength{\oddsidemargin}{0in}
\setlength{\textwidth}{6.8in}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\maketitle

% Note: Khi đăng Blog -> Làm đơn giản và trọng tâm nhất có thể.
\begin{summarybox}
Bài viết này giải mã Convolutional Neural Networks (CNN) từ góc độ tư duy bộ lọc (filter perspective)
thay vì chỉ liệt kê công thức toán học.
mình sẽ đi từ hạn chế của mạng nơ-ron truyền thống đến cách CNN "nhìn" thế giới,
cơ chế lan truyền ngược phức tạp và các kỹ thuật nâng cao như 1x1 Convolution. \\


\textbf{Phần 1: Tại sao Neural Network truyền thống (MLP) "bó tay" với hình ảnh?} \\ \\
\textbf{Phần 2: Tư duy Bộ lọc (Filter Perspective) \& Cơ chế cơ bản} \\ \\
\textbf{Phần 3: Kiến trúc CNN - Xếp tầng các khối xử lý} \\ \\
\textbf{Phần 4: CNN Backpropagation \& Sự thật về phép xoay Kernel} \\ \\
\textbf{Phần 5: CNN Nâng cao - 1x1 Convolution \& Phân biệt chiều không gian}
\end{summarybox}

% --- Blog Outline ---
\section{Phần 1: Tại sao Neural Network truyền thống (MLP) "bó tay" với hình ảnh?}

Trước khi nói về giải pháp, hãy nhìn vào vấn đề. Tại sao mình không thể cứ thế ném một bức ảnh vào mạng nơ-ron đa tầng (MLP) thông thường? Để hiểu điều này, ta cần "mổ xẻ" cách máy tính lưu trữ một bức ảnh.

\subsection{Bản chất của màu sắc (RGB Color)}
Trong thị giác máy tính, màu sắc không phải là khái niệm trừu tượng mà là các con số cụ thể được định nghĩa bởi hệ màu \textbf{RGB} (Red - Green - Blue). Mỗi kênh màu này đại diện cho một sắc độ riêng biệt với giá trị chạy từ 0 đến 255 (tương ứng với 256 mức độ khác nhau). Bằng cách phối hợp cường độ sáng của 3 kênh này lại, máy tính có thể tái tạo hàng triệu màu sắc khác nhau mà mắt người nhìn thấy được.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\linewidth]{imgs/colors.png}
\end{figure}

\subsection{Biểu diễn ảnh dưới dạng Ma trận (Matrix Representation)}
Một bức ảnh kỹ thuật số thực chất là một lưới các điểm ảnh (pixels). Ví dụ, một bức ảnh kích thước $800 \times 600$ sẽ được cấu thành từ 800 hàng và 600 cột.
\begin{figure}[H] % [H] để ép ảnh nằm ngay tại vị trí này
    % Hàng 1: Ma trận tổng quát và Ma trận tuple
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{imgs/mtr1.png}
        \caption{Ma trận tổng quát $W_{i,j}$}
        \label{fig:mtr1}
    \end{subfigure}
    \hfill % Đẩy 2 ảnh ra xa nhau để căn lề 2 bên
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{imgs/mtr2.png}
        \caption{Giá trị pixel là bộ 3 số (R,G,B)}
        \label{fig:mtr2}
    \end{subfigure}

    \vspace{0.5cm} % Khoảng cách giữa 2 hàng

	Tại mỗi vị trí tọa độ $(i, j)$, giá trị pixel $w_{ij}$ không tồn tại dưới dạng một số đơn lẻ mà là một bộ ba giá trị $(r_{ij}, g_{ij}, b_{ij})$,
	ví dụ như $(0, 233, 256)$ để tạo ra màu xanh ngọc. Để tối ưu hóa cho việc lưu trữ và xử lý tính toán,
	máy tính thường không gộp chung mà tách riêng các giá trị này thành 3 ma trận độc lập tương ứng với 3 kênh màu Đỏ, Xanh lá và Xanh dương. \\ \\

    % Hàng 2: Tách kênh màu (Dùng ảnh mtr3 hoặc rgb_mtr tùy bạn chọn cái nào rõ hơn)
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{imgs/mtr3.png}
        \caption{Tách một ảnh màu thành 3 ma trận R, G, B riêng biệt}
        \label{fig:mtr3}
    \end{subfigure}

    \vspace{0.5cm} % Khoảng cách giữa 2 hàng

    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{imgs/rgb_mtr.png}
    \end{subfigure}
\end{figure}

\subsection{Từ Ma trận đến Tensor}
Khái niệm \textbf{Tensor} xuất hiện để tổng quát hóa các cấu trúc dữ liệu này theo số chiều.
Trong khi Vector là Tensor 1D và Ma trận là Tensor 2D (như ảnh xám chỉ cần một ma trận duy nhất để biểu diễn độ sáng từ đen sang trắng),
thì ảnh màu lại phức tạp hơn. Vì ảnh màu được tạo thành từ việc chồng 3 ma trận R, G, B lên nhau (collapse on top of each other),
nó được định nghĩa là một \textbf{Tensor 3D} với kích thước $Height \times Width \times Depth$ (trong đó Depth = 3).
\begin{figure}[H]
	\centering
    \includegraphics[width=0.9\linewidth]{imgs/3d_tensor.png}
\end{figure}
Việc hiểu đúng chiều sâu (Depth) của Tensor là mấu chốt để hiểu cách CNN vận hành sau này.
% Tensor Source: https://lisaong.github.io/mldds-courseware/01_GettingStarted/numpy-tensor-slicing.slides.html

\subsection{Sự bùng nổ tham số (The Parameter Explosion)}
Chính cấu trúc Tensor 3D này là nguyên nhân khiến mạng MLP truyền thống "đầu hàng".
Chỉ thử làm một phép tính với bức ảnh rất nhỏ kích thước $64 \times 64$: tổng số giá trị đầu vào sẽ là $64 \times 64 \times 3 = 12,288$.
Nếu ta kết nối đầu vào này vào một lớp ẩn chỉ gồm 1,000 nơ-ron theo cách kết nối toàn bộ (fully connected) của MLP,
số lượng trọng số cần học sẽ lên tới hơn \textbf{12 triệu} tham số ($12,288 \times 1,000$).
Khối lượng tính toán khổng lồ này không chỉ làm chậm hệ thống mà còn dẫn đến hiện tượng Overfitting nghiêm trọng,
buộc mình phải tìm đến giải pháp thông minh hơn là CNN để xử lý cấu trúc Tensor một cách hiệu quả.


\section{Phần 2: Tư duy Bộ lọc (Filter Perspective) \& Cơ chế cơ bản}
Đây là phần trọng tâm để hiểu CNN từ gốc rễ. Thay vì tư duy theo kiểu "kết nối tất cả mọi thứ" như mạng MLP truyền thống, CNN tiếp cận hình ảnh theo cách con người quan sát: tìm kiếm các đặc trưng (features).


\subsection{Kernel/Filter là gì? - Chiếc "đèn pin" soi mẫu}
Trong thế giới của CNN, để máy tính hiểu được một bức ảnh, nó cần biết được những đặc trưng nào làm cho bức ảnh đó trở nên độc nhất.
Thay vì phân tích từng điểm ảnh riêng lẻ, mình sử dụng \textbf{Kernel} (hay Filter) - một ma trận nhỏ (thường là $3 \times 3$ hoặc $5 \times 5$).
Kernel hoạt động như một "cửa sổ trượt", di chuyển quét qua toàn bộ bức ảnh để tìm kiếm sự tồn tại của các mẫu cụ thể,
ví dụ như một đường cong, một cạnh dọc, hay một đường chéo. Để hiểu rõ, mình đi vào 1 ví dụ luon nhé.

\subsection{Cơ chế khớp mẫu (Feature Matching) - Bí mật của phép tích chập}
Hãy hình dung mình muốn dạy máy tính nhận diện chữ "X". Chữ "X" được cấu tạo bởi hai đường chéo bắt chéo nhau.
Một Kernel được thiết kế để tìm "đường chéo trái" sẽ có các giá trị dương (ví dụ: 1) nằm trên đường chéo đó và các giá trị âm (ví dụ: -1) ở những vị trí còn lại. (Note: ma trận trắng đại diện cho kết quả sau khi áp dụng kernel)
\begin{figure}[H]
	\centering
    \includegraphics[width=0.8\linewidth]{imgs/filt2.png}
\end{figure}
Đây là phần trọng tâm để hiểu CNN từ gốc rễ.
Thay vì tư duy theo kiểu "kết nối tất cả mọi thứ" như mạng MLP truyền thống,
CNN tiếp cận hình ảnh theo cách con người quan sát: tìm kiếm các đặc trưng (features). \\

Quá trình "Filtering" (lọc) diễn ra như sau:
\begin{figure}[H]
	\centering
    \includegraphics[width=0.8\linewidth]{imgs/filt1.png}
\end{figure}

\begin{enumerate}
    \item \textbf{Line up}: Đặt Kernel chồng lên một vùng ảnh cùng kích thước.
    \item \textbf{Multiply}: Nhân từng giá trị pixel của ảnh với giá trị tương ứng trong Kernel (Element-wise multiplication).
    \item \textbf{Add}: Cộng tổng tất cả các kết quả lại và chia trung bình.
\end{enumerate}

\textbf{Kết quả:}
\begin{figure}[H]
	\centering
    \includegraphics[width=0.7\linewidth]{imgs/filt2_emphasize.png}
\end{figure}
\begin{itemize}
    \item Nếu vùng ảnh bên dưới thực sự có hình đường chéo (khớp với Kernel), phép nhân sẽ tạo ra các số dương lớn $\rightarrow$ Kết quả tổng rất cao (ví dụ: 1.0 hoặc 100\%). Ta nói pattern đó đã được "kích hoạt" (activated).
    \item Nếu vùng ảnh không khớp (ví dụ: Kernel đường chéo nhưng đặt lên vùng ảnh đường thẳng đứng), các phép nhân dương và âm sẽ triệt tiêu lẫn nhau $\rightarrow$ Kết quả tổng xấp xỉ 0 hoặc âm.
	\item \href{https://nttuan8.com/bai-6-convolutional-neural-network/}{Ví dụ tương tự đối với ảnh 3D}.
\end{itemize}

\textbf{Minh họa các loại Filter khác nhau trích xuất các kiểu đặc trưng khác nhau}
\begin{figure}[H]
	\centering
    \includegraphics[width=0.55\linewidth]{imgs/3ker.png}
\end{figure}

\pagebreak

\subsection{Các phép toán kiểm soát Bộ lọc (Convolution Operation)}

\textbf{Stride (Bước nhảy - ô vuông kernel di chuyển bao nhiêu bước mỗi lượt):}
Đây là khoảng cách mà Kernel di chuyển sau mỗi lần tính toán.
Nếu $Stride = 1$, Kernel nhích từng pixel một, giữ độ chi tiết cao nhất. Nhưng nếu ta tăng $Stride > 1$ (ví dụ: $Stride = 2$), Kernel sẽ "nhảy cóc" qua các pixel. Điều này có tác dụng giảm kích thước dữ liệu đầu ra (Downsampling) ngay lập tức mà không cần lớp Pooling, giống như việc ta lướt nhanh qua một văn bản để nắm ý chính thay vì đọc từng chữ. \\

\begin{figure}[H]
	\centering
    \includegraphics[width=0.45\linewidth]{imgs/stride.png}
	\caption{Với phần in đậm là tâm của kernel, với stride = 2, kernel sẽ đi 2 bước tính từ tâm. Nếu kernel là 2x2 thì lấy pixel trên cùng bên trái làm tâm}
\end{figure}


\textbf{Padding (Lề - Pixel được bọc thêm bên ngoài ảnh):}
Khi Kernel trượt ở rìa bức ảnh, nó thường bị thiếu hụt dữ liệu (không đủ kích thước $3 \times 3$ để nhân). Điều này dẫn đến hai vấn đề: ảnh bị thu nhỏ lại sau mỗi lớp tích chập và thông tin ở rìa ảnh bị mất mát.
Giải pháp là \textbf{Zero-Padding}: thêm một viền các số 0 bao quanh ảnh gốc.
Lớp "đệm" này cho phép Kernel đặt tâm ngay tại pixel ngoài cùng, giúp giữ nguyên kích thước không gian ($Height \times Width$) của Feature Map đầu ra. \\
\begin{figure}[H]
	\centering
    \includegraphics[width=0.45\linewidth]{imgs/pad.png}
\end{figure}


\textbf{Minh họa Padding và Stride:}
Note: kích thước ảnh hoặc feature map (i.e. ảnh sau khi áp dụng convolution) phải lớn tương ứng để áp dụng stride.
\begin{figure}[H]
	\centering
    \includegraphics[width=0.8\linewidth]{imgs/p&s.png}
\end{figure}


\textbf{Công thức kích thước đầu ra:}
Để thiết kế kiến trúc mạng chính xác, ta cần tính toán được kích thước của ma trận sau khi qua lớp Conv:
$$ Output = \frac{Input - Filter + 2 \times Padding}{Stride} + 1 $$
Trong đó: $Input$ là kích thước ảnh đầu vào, $Filter$ là kích thước Kernel, $Padding$ là số lớp viền thêm vào, và $Stride$ là bước nhảy.
\begin{figure}[H]
	\centering
    \includegraphics[width=0.8\linewidth]{imgs/p&s2.png}
\end{figure}



Việc trượt Kernel qua ảnh không phải lúc nào cũng tuỳ ý, nó được kiểm soát bởi các tham số toán học nghiêm ngặt để định hình dữ liệu đầu ra. \\

\textbf{Pooling (Gộp đặc trưng):}
\begin{itemize}
	\item \textbf{Max Pooling:} Chỉ giữ lại giá trị lớn nhất trong vùng (đặc trưng nổi bật nhất), giúp nén ảnh và giảm tải tính toán nhưng vẫn giữ được thông tin cốt lõi.
	\item \textbf{Average Pooling:} Lấy giá trị trung bình của toàn bộ các pixel trong vùng, nhằm tổng hợp thông tin một cách “mềm”, phản ánh mức độ hiện diện trung bình của đặc trưng thay vì chỉ tập trung vào điểm mạnh nhất.
\end{itemize}
\begin{figure}[H]
	\centering
    \includegraphics[width=0.45\linewidth]{imgs/buling.png}
\end{figure}


\section{Phần 3: Kiến trúc CNN - Từ "Phân rã đặc trưng" đến "Hội đồng bỏ phiếu"}

Nếu như Kernel là công cụ để tìm kiếm, thì Kiến trúc CNN chính là chiến lược để sử dụng những tìm kiếm đó.
Bản chất của CNN không phải là nhìn thấy ngay con mèo hay chiếc xe hơi, mà là một quá trình \textbf{phân rã và tái tạo}.

\subsection{Bản chất của CNN: Chia để trị}
Thay vì cố gắng nhận diện toàn bộ vật thể ngay lập tức, nó chia nhỏ bài toán thành các tầng đặc trưng (Feature Hierarchy) từ đơn giản đến phức tạp:
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{imgs/conv_fea.png}
    \caption{Minh họa sự phân cấp đặc trưng trong CNN: Từ các cạnh đơn giản (trái) đến các chi tiết vật thể phức tạp (phải).}
\end{figure}
\begin{itemize}
    \item \textbf{Tầng thấp (Low-level features):} Ở các lớp đầu tiên, mạng chỉ nhìn thấy các chi tiết sơ khai nhất như \textbf{cạnh, đường biên, màu sắc}. Trên ảnh minh họa, chúng thường trông giống như các vạch kẻ sọc hoặc nhiễu.
    \item \textbf{Tầng giữa (Mid-level features):} Các lớp tiếp theo ghép nối các cạnh này lại thành các \textbf{họa tiết, hình thù cơ bản} như đường cong, góc vuông, hình tròn (ví dụ: mắt, bánh xe, hoặc một phần của con số).
    \item \textbf{Tầng cao (High-level features):} Lớp cuối cùng tổng hợp chúng thành các \textbf{bộ phận hoàn chỉnh} để nhận diện vật thể.
\end{itemize}

Mỗi lớp đóng vai trò như một bộ lọc tinh vi hơn lớp trước đó, biến đổi các pixel vô nghĩa thành các đặc trưng có ý nghĩa phân loại.


\subsection{ReLU (Rectified Linear Unit) - Người gác cổng của các lá phiếu}
Sau mỗi lần Kernel quét qua ảnh (phép tích chập), chúng ta thu được một bản đồ các giá trị. Có nơi giá trị rất dương (khớp mẫu), có nơi giá trị âm (ngược mẫu). Lúc này, \textbf{ReLU} xuất hiện với vai trò cực kỳ quan trọng nhưng thường bị hiểu nhầm là chỉ để "làm toán".
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{imgs/relu_fm.png}
\end{figure}
Theo góc nhìn bản chất, ReLU giúp mô hình trả lời câu hỏi: \textbf{"Đặc trưng này có xuất hiện hay không?"}.
\begin{itemize}
    \item Nếu kết quả là số dương: "Có, tôi tìm thấy một cái cạnh ở đây!". Chúng ta giữ nguyên giá trị đó.
    \item Nếu kết quả là số âm: "Không, hoặc nó ngược lại với cái tôi tìm". ReLU sẽ biến nó thành số 0.
\end{itemize}
Tại sao phải loại bỏ số âm? Trong cơ chế bỏ phiếu (voting), chúng ta chỉ quan tâm đến sự hiện diện của các bằng chứng (evidence). Việc giữ lại các giá trị âm (nhiễu/không khớp) sẽ làm loãng thông tin khi mạng cố gắng tổng hợp các đặc trưng lại với nhau. ReLU giúp thanh lọc tín hiệu, đảm bảo rằng các lớp sau chỉ nhận được những "bằng chứng" chắc chắn nhất.

\subsection{Receptive Field - Tầm nhìn mở rộng}
Khi chúng ta xếp chồng (stack) các lớp Convolution và Pooling lên nhau, một hiện tượng thú vị xảy ra: \textbf{Receptive Field} (Vùng cảm nhận) của nơ-ron ngày càng lớn.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\linewidth]{imgs/fullConv.png}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\linewidth]{imgs/maxPool.png}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\linewidth]{imgs/reLus.png}
\end{figure}
\begin{figure}[H]
    \centering
	\includegraphics[width=0.8\linewidth]{imgs/stackedLayer.png}
	\caption{Một điểm pixel ở lớp Conv 1 chỉ đại diện cho vùng $3 \times 3$ của ảnh gốc.}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{imgs/stackedLayer2.png}
\end{figure}

Nhưng một điểm pixel ở lớp Conv 3 (sau khi qua Pooling) lại đại diện cho vùng $12 \times 12$ hoặc lớn hơn của ảnh gốc.
Chính nhờ cơ chế này, các lớp sâu (Deep Layers) có thể "nhìn" thấy tổng thể bức ảnh để đưa ra quyết định, dù chúng được xây dựng từ những bộ lọc rất nhỏ ban đầu.



\subsection{Góc nhìn "Hội đồng bỏ phiếu" (A List of Votes)}
Cuối cùng, sau khi đi qua toàn bộ quy trình: Tích chập (tìm đặc trưng) $\rightarrow$ ReLU (lọc bằng chứng) $\rightarrow$ Pooling (nén thông tin), dữ liệu từ dạng hình ảnh 3D sẽ được dát phẳng (Flatten) thành một danh sách dài các giá trị đặc trưng cao cấp. Lúc này, lớp Fully Connected (FC) đóng vai trò như một "Hội đồng bỏ phiếu", nơi mỗi đặc trưng trở thành một "cử tri" đưa ra quyết định cuối cùng. Ví dụ: \textit{"Tôi thấy bánh xe (giá trị cao) + Tôi thấy cửa kính (giá trị cao) $\rightarrow$ Tôi bỏ phiếu cho lớp: Ô TÔ"}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{imgs/nn_vote.png}
\end{figure}


Một câu hỏi quan trọng thường bị bỏ qua: Tại sao ở các lớp ẩn này, ta lại ưu tiên dùng ReLU thay vì hàm Sigmoid truyền thống? Câu trả lời nằm ở khả năng "học ngược" của mạng. Hàm Sigmoid nén mọi giá trị vào khoảng $(0, 1)$, điều này vô tình khiến tín hiệu đạo hàm bị nhỏ dần qua từng lớp, dẫn đến vấn đề \textbf{Biến mất đạo hàm (Gradient Vanishing)}, làm mạng "quên" mất các đặc trưng đầu vào. Ngược lại, ReLU hoạt động như một "cổng dẫn truyền thẳng": với các giá trị dương, đạo hàm bằng 1. Điều này không chỉ khắc phục triệt để vấn đề biến mất đạo hàm mà còn giúp tín hiệu \textbf{truy ngược (flip backward)} một cách nguyên vẹn từ lớp cuối cùng về các lớp đầu. Nhờ đó, MLP có thể học và điều chỉnh các mẫu (patterns) theo chiều ngược lại một cách hiệu quả, đảm bảo rằng mối liên kết giữa "nguyên nhân" (đặc trưng ảnh) và "kết quả" (nhãn phân loại) luôn được duy trì chặt chẽ trong suốt quá trình huấn luyện.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{imgs/cls_mlp.png}
    \caption{Cơ chế bỏ phiếu của lớp Fully Connected: Các đặc trưng được tổng hợp để đưa ra xác suất phân loại.}
\end{figure}


\section{Phần 4: CNN Backpropagation \& Sự thật về phép xoay Kernel}
Đây là phần "khó nhằn" nhất nhưng cũng là nơi chứa đựng vẻ đẹp toán học của CNN. Nếu như Forward Pass là quá trình máy tính "nhìn" bức ảnh, thì Backward Pass là lúc nó "tự kiểm điểm" để rút kinh nghiệm.

Chúng ta sẽ đi sâu vào việc làm thế nào sai số (Loss) được truyền ngược từ lớp cuối cùng về các lớp đầu để cập nhật bộ lọc (Kernel).

\subsection{Mục tiêu của chúng ta}
Giả sử ta có một lớp Convolution đơn giản:
$$ Y = X * K $$
Trong đó:
\begin{itemize}
    \item $X$: Ảnh đầu vào (Input).
    \item $K$: Bộ lọc (Kernel/Filter).
    \item $Y$: Bản đồ đặc trưng đầu ra (Output Feature Map).
    \item $L$: Hàm mất mát (Loss Function) cuối cùng của mạng.
\end{itemize}

Nhiệm vụ của Backpropagation là tìm ra hai đạo hàm riêng (Gradients) quan trọng:
\begin{enumerate}
    \item $\frac{\partial L}{\partial K}$: Để cập nhật trọng số của bộ lọc (giúp máy học được đặc trưng tốt hơn).
    \item $\frac{\partial L}{\partial X}$: Để truyền sai số về cho lớp đứng trước nó (tiếp tục chuỗi Backprop).
\end{enumerate}

\subsection{Tính đạo hàm cho Bộ lọc ($\frac{\partial L}{\partial K}$)}
Tưởng tượng Kernel $K$ đang trượt trên ảnh $X$. Mỗi lần trượt, nó tạo ra một giá trị trên $Y$. Vì vậy, một trọng số trong Kernel sẽ đóng góp vào tất cả các pixel đầu ra mà nó đi qua.

Theo quy tắc chuỗi (Chain Rule), đạo hàm của lỗi đối với một trọng số $w$ trong Kernel là tổng hợp của tất cả các lỗi mà trọng số đó gây ra trên toàn bộ bản đồ đầu ra $Y$:
$$ \frac{\partial L}{\partial K_{ij}} = \sum_{m} \sum_{n} \frac{\partial L}{\partial Y_{mn}} \cdot \frac{\partial Y_{mn}}{\partial K_{ij}} $$

Điều thú vị là: Khi bạn triển khai công thức này ra, nó chính là một phép Cross-Correlation giữa ảnh đầu vào $X$ và bản đồ lỗi $\frac{\partial L}{\partial Y}$.
\begin{summarybox}
\textbf{Trực giác:} Để biết nên sửa Kernel thế nào, ta lấy "Bản đồ lỗi" ướm lên "Ảnh gốc". Nơi nào ảnh gốc có giá trị lớn mà lỗi cũng lớn, nghĩa là Kernel tại đó cần được điều chỉnh mạnh tay nhất.
\end{summarybox}

\subsection{Tính đạo hàm cho Đầu vào ($\frac{\partial L}{\partial X}$) - Sự xuất hiện của Rot180}
Đây là phần gây lú lẫn nhất và cũng là lý do tại sao nhiều tài liệu toán học lại nhắc đến việc "xoay 180 độ".

Để tính gradient cho lớp đầu vào $X$ (nhằm truyền về lớp trước), ta cần biết mỗi pixel $x_{ij}$ đã ảnh hưởng đến bao nhiêu pixel trên đầu ra $Y$.
Theo toán học, công thức để tính đạo hàm này chính là phép tích chập (Convolution) giữa bản đồ lỗi $\frac{\partial L}{\partial Y}$ (được lót thêm viền - padded) với Kernel đã bị xoay 180 độ ($rot180(K)$).

$$ \frac{\partial L}{\partial X} = \frac{\partial L}{\partial Y} * rot180(K) $$

Tại sao phải xoay?
\begin{itemize}
    \item Trong quá trình Forward (đi tới), pixel $x_{11}$ nhân với $k_{11}$.
    \item Nhưng khi Backward (đi lùi), để truy ngược dòng chảy từ $Y$ về $X$, các mối liên hệ không gian bị đảo ngược. Phần tử góc trên-trái của Kernel lúc đi tới thực chất lại tương ứng với phần tử góc dưới-phải khi ta xét từ góc độ lan truyền ngược.
\end{itemize}

\subsection{Sự thật về Cross-Correlation vs. Convolution}
Trong các thư viện Deep Learning thực tế (như PyTorch hay TensorFlow), có một sự khác biệt nhỏ giữa lý thuyết và thực hành:
\begin{itemize}
    \item Lý thuyết Toán học: Phép Convolution chuẩn $(f * g)$ yêu cầu phải lật ngược Kernel 180 độ trước khi trượt.
    \item Thực tế Code: Hầu hết các thư viện sử dụng phép Cross-Correlation (trượt mà KHÔNG lật) cho quá trình Forward Pass để giảm chi phí tính toán.
\end{itemize}

Chính vì Forward Pass dùng Cross-Correlation (không xoay), nên để đảm bảo tính đúng đắn của đạo hàm, quá trình Backward Pass bắt buộc phải thực hiện phép toán ngược lại - chính là Convolution thực sự (tức là Cross-Correlation với Kernel xoay 180 độ).

\begin{summarybox}
\textbf{Tóm lại quy trình chuẩn:}
\begin{itemize}
    \item \textbf{Forward:} Trượt Kernel thẳng (Cross-Correlation).
    \item \textbf{Backward (tính cho X):} Trượt Kernel xoay 180 độ (Convolution chuẩn).
\end{itemize}
Đây là vẻ đẹp của sự đối xứng trong toán học: Anh đi tới bằng cách trượt xuôi, thì anh phải đi lùi bằng cách trượt ngược để mọi thứ khớp lại hoàn hảo.
\end{summarybox}


\section{Phần 5: CNN Nâng cao - 1x1 Convolution \& Phân biệt chiều không gian} % Đã sửa lỗi & thành \&
Mở rộng kiến thức sang các khái niệm hiện đại và sửa chữa các hiểu lầm phổ biến.
\begin{itemize}
    \item \textbf{Phân biệt 2D vs 3D CNN:}
    \begin{itemize}
        \item Làm rõ hiểu lầm: Ảnh màu RGB (3 kênh) vẫn dùng 2D CNN (xử lý không gian Height-Width).
        \item 3D CNN thực sự dùng cho dữ liệu video (thêm chiều thời gian/Temporal).
    \end{itemize}
    \item \textbf{Phép màu của $1 \times 1$ Convolution:}
    \begin{itemize}
        \item Nó hoạt động như một "Single Neuron" áp dụng lên chiều sâu (channels) của từng pixel.
        \item Ứng dụng: Giảm số chiều dữ liệu (Dimensionality Reduction) và trộn thông tin giữa các kênh màu (Channel Pooling) mà không thay đổi kích thước không gian.
    \end{itemize}
\end{itemize}

\end{document}
