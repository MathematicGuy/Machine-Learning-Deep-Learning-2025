{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6547f51",
   "metadata": {},
   "source": [
    "Code xong đóng tiền học"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a90b65a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83ed594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'gpu')\n",
    "print('current device ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d80d1334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(10, 10)\n",
    "tensor_on_device = tensor.to(device)\n",
    "print(tensor_on_device.device) # 0 mean using is the first prioritize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e5ba39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1797927f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90484553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Zero tensor: \n",
      " tensor([[0, 0],\n",
      "        [0, 0]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(f\"Ones tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_ones = torch.zeros_like(x_data)\n",
    "print(f\"Zero tensor: \\n {x_ones} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5046fefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.8844, 0.3451, 0.2813],\n",
      "        [0.2881, 0.0779, 0.5951]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3, )\n",
    "rand_tensor = torch.rand(shape) # create random number\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a811e160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e6d8e6",
   "metadata": {},
   "source": [
    "### Operations on Tensor\n",
    "\n",
    "There are over 1200 tensor operations, including arithmetic, linear algebra, matrix manipulation (tranposing, indexing, slicing), samplings and more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab711a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef855968",
   "metadata": {},
   "source": [
    "By default, tensor are created and stores on the CPU. We need to explicitly more tensors to the accelerator using `.to` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "052f0d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current accelarator: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.accelerator\n",
    "\n",
    "if torch.accelerator.is_available():\n",
    "\taccelarator = torch.accelerator.current_accelerator()\n",
    "\ttensor = tensor.to(accelarator)\n",
    "\tprint('current accelarator:', accelarator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baa77233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision import datasets\n",
    "# from torchvision.transforms import ToTensor\n",
    "\n",
    "# # Download training data from open datasets.\n",
    "# training_data = datasets.FashionMNIST(\n",
    "#     root=\"data\",\n",
    "#     train=True,\n",
    "#     download=True,\n",
    "#     transform=ToTensor(),\n",
    "# )\n",
    "\n",
    "# # Download test data from open datasets.\n",
    "# test_data = datasets.FashionMNIST(\n",
    "#     root=\"data\",\n",
    "#     train=False,\n",
    "#     download=True,\n",
    "#     transform=ToTensor(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49991a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "iris=load_iris()\n",
    "X = torch.tensor(iris.data, dtype=torch.float32) # shape (150, 4)\n",
    "y = torch.tensor(iris.data, dtype=torch.long) # class labels 0, 1, 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c74f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# Create a Dataset and DataLoader for training/validation split\n",
    "dataset = TensorDataset(X, y)\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11dc3a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([16, 4])\n",
      "Shape of y: torch.Size([16, 4]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "\t\"\"\"\n",
    " \t\tN: Number of images in the batch\n",
    "\t\tC: Number of channels in the image (e.g., 1 for grayscale, 3 for RGB)\n",
    "\t\tH: Height of the image\n",
    "\t\tW: Width of the image\n",
    "\t\"\"\"\n",
    "\tprint(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "\tprint(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94a797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You just called __repr__\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "You just called __repr__"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Animal:\n",
    " \tdef __init__(self, animal, breed):\n",
    "\t\tself.animal = animal\n",
    "\t\tself.breed = breed\n",
    "\t\t\n",
    "\tdef __str__(self):\n",
    "\t\treturn \"You just called __str__\" # display information in print\n",
    "\n",
    "\tdef __repr__(self): #? repr mean string representation\n",
    "     \t# also display information in print if __str__ is not define\n",
    "\t\t# display raw information\n",
    "  \t\treturn \"You just called __repr__\" \n",
    "\n",
    "a = Animal(\"Cat\", \"Three eyes\")\n",
    "print(a)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1625fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        #? Store the state of a NeuralNet Object. We can define many Object using this single class\n",
    "        super().__init__() # inherit pytorch nn library\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf73ec1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e7a17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
